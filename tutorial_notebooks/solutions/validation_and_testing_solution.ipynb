{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "lLy5PsIql9A5"
      },
      "source": [
        "# 5. Validation & Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6L-ynOvokKT"
      },
      "source": [
        "Welcome to the fifth notebook of our six part series part of our tutorial on Deep Learning for Human Activity Recognition. Within the last notebook you learned:\n",
        "\n",
        "- How do I define a sample neural network architecture in PyTorch? \n",
        "- What additional preprocessing do I need to apply to my data to fed it into my network?\n",
        "- How do I define a train loop which trains my neural network?\n",
        "\n",
        "This notebook will teach you everything you need to know about validation and testing. When building a predictive pipeline there are a lot of parameters which one needs to set before comencing the actual training. Coming up with a suitable set of hyperparameters is called hypertuning. In order to gain feedback whether the applied hyperparameters are a good choice, we check the predictive performance of our model on the validation set. This is called validation.\n",
        "\n",
        "Now you might ask yourself: Solely relying and tuning based on the validation scores would inherit that your trained model would end up being too well optimized on the validation set and thus not general anymore, right? If asked yourself that question, then you are 100% right in your assumption! This is what we call overfitting and is one of the major pitfalls in Machine Learning.Overfitting your model results in bad prediction performance on unseen data. \n",
        "\n",
        "We therefore need a third dataset, called the test dataset. The test dataset is a part of the initial dataset which you keep separate from all optimization steps. It is only used to gain insights on the predictive performance of the model and must not (!) be used as a reference for tuning hyperparameters. As we mentioned in during the theoretical parts of this tutorial, (supervised) Deep Learning, in our opinion, is just a fancy word for function approximation. If your model performs both well during validation and testing, it is a general function which properly approximates the underlying function.\n",
        "\n",
        "After completing this notebook you will be answer the following questions:\n",
        "- How do I split my initial dataset into a train, validation and test dataset?\n",
        "- What validation methods exist in Human Activity Recognition? How are they performed?\n",
        "- How is testing usually performed?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4fWjW5V0_MT"
      },
      "source": [
        "## 5.1. Important Remarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkhCF6Pd1B1Z"
      },
      "source": [
        "If you are accessing this tutorial via [Google Colab](https://colab.research.google.com/github/mariusbock/dl-for-har/blob/main/tutorial_notebooks/training.ipynb), first make sure to use Google Colab in English. This will help us to better assist you with issues that might arise during the tutorial. There are two ways to change the default language if it isn't English already:\n",
        "1. On Google Colab, go to `Help` -> `View in English` \n",
        "2. Change the default language of your browser to `English`.\n",
        "\n",
        "To also ease the communication when communicating errors, enable line numbers within the settings of Colab.\n",
        "\n",
        "1. On Google Colab, go to `Tools` -> `Settings` -> `Editor` -> `Show line numbers`\n",
        "\n",
        "In general, we strongly advise you to use Google Colab as it provides you with a working Python distribution as well as free GPU resources. To make Colab use GPUs, you need to change the current notebooks runtime type via:\n",
        "\n",
        "- `Runtime` -> `Change runtime type` -> `Dropdown` -> `GPU` -> `Save`\n",
        "\n",
        "**Hint:** you can auto-complete code in Colab via `ctrl` + `spacebar`\n",
        "\n",
        "For the live tutorial, we require all participants to use Colab. If you decide to rerun the tutorial at later points and rather want to have it run locally on your machine, feel free to clone our [GitHub repository](https://github.com/mariusbock/dl-for-har).\n",
        "\n",
        "To get started with this notebook, you need to first run the code cell below. Please set `use_colab` to be `True` if you are accessing this notebook via Colab. If not, please set it to `False`. This code cell will make sure that imports from our GitHub repository will work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "si3n5Sc51L-D",
        "outputId": "249cd3be-1f9e-4a7e-ffb6-8e184bb0889f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'dl-for-har'...\n",
            "remote: Enumerating objects: 1534, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 1534 (delta 49), reused 34 (delta 28), pack-reused 1447\u001b[K\n",
            "Receiving objects: 100% (1534/1534), 35.64 MiB | 13.12 MiB/s, done.\n",
            "Resolving deltas: 100% (872/872), done.\n",
            "/content/dl-for-har\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "use_colab = True\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "\n",
        "if use_colab:\n",
        "    # move to content directory and remove directory for a clean start \n",
        "    %cd /content/         \n",
        "    %rm -rf dl-for-har\n",
        "    # clone package repository (will throw error if already cloned)\n",
        "    !git clone https://github.com/mariusbock/dl-for-har.git\n",
        "    # navigate to dl-for-har directory\n",
        "    %cd dl-for-har/       \n",
        "else:\n",
        "    os.chdir(module_path)\n",
        "    \n",
        "# this statement is needed so that we can use the methods of the DL-ARC pipeline\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIjrK-KE1iDL"
      },
      "source": [
        "## 5.1. Splitting your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrLU2e9H1oAX"
      },
      "source": [
        "Within the first part of this notebook we will split our data in the above mentioned three datasets, namely the train, validation and test dataset. There are multiple ways how to split the data into the two respective datasets, for example:\n",
        "\n",
        "- **Subject-wise:** split according to participants within the dataset. This means that we are reserving certain subjects to be included in the train, validation and test set respectively. For example, given that there are a total of 10 subjects, you could use 6 subjects for trainig, 2 subjects for validation and 2 subjects for testing.\n",
        "- **Percentage-wise:** state how large percentage-wise your train, validation and test dataset should be compared to the full dataset. For example, you could use 60% of your data for training, 20% for validation and 20% for testing. The three splits can also be chosen to be stratified, meaning that the relative label distribution within each of the two dataset is kept the same as in the full dataset. Note that stratifiying your data would require the data to be shuffled.\n",
        "- **Record-wise:** state how many records should be in your train, validation and test dataset should be contained, i.e. define two cutoff points. For example, given that there are 1 million records in your full dataset, you could have the first 600 thousand records to be contained in the train dataset, the next 200 thousand in the validation dataset and the remaining 200 thousand records to be contained in the test dataset.\n",
        "\n",
        "**WARNING:** shuffling your dataset during splitting (which is e.g. needed for stratified splits) will destroy the time-dependencies among the data records. To minimize this effect, apply a sliding window on top of your data before splitting. This way, time-dependencies will at least be preserved within the windows. While working on this notebook, we will notify you when this is necessary.\n",
        "\n",
        "To keep things simple and fast, we will be splitting our data subject-wise. We will use the first data of the first subject for training, the data of the second subject for validation and the data of the third subject for testing. Your first task will be to perform said split. Note that we already imported the dataset for you using the `load_dataset()` function, which is part of the DL-ARC feature stack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIAoSI0Ql9BC"
      },
      "source": [
        "### Task 1: Split the data into train, validation and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_QkR_bHl9BC"
      },
      "source": [
        "1. Define the `train` dataset to be the data of the first subject, i.e. with `subject_identifier = 0`. (`lines 13-14`)\n",
        "2. Define the `valid` dataset to be the data of the second subject, i.e. with `subject_identifier = 1`. (`lines 15-16`)\n",
        "3. Define the `test` dataset to be the data of the third subject, i.e. with `subject_identifier = 2`. (`lines 17-18`)\n",
        "4. Define a fourth dataset being a concatenated version of the `train` and `valid` dataset called `train_valid`. You will need this dataset for some of the validation methods. Use `np.concatenate()` in order to concat the two numpy arrays along `axis=0`. (`lines 20-21`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "el2x8KMJl9BE",
        "outputId": "13772ccc-cf16-430e-cee0-7879dd84a6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dataset files ...\n",
            "Full dataset with size: | X (659260, 4) | y (659260,) | \n",
            " ..from file data/rwhar_3sbjs_data.csv\n",
            "\n",
            "Shape of the train, validation and test dataset:\n",
            "(221621, 5) (208835, 5) (228804, 5)\n",
            "\n",
            "Shape of the concatenated train_valid dataset:\n",
            "(430456, 5)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from data_processing.preprocess_data import load_dataset\n",
        "\n",
        "\n",
        "# data loading (we are using a predefined method called load_dataset, which is part of the DL-ARC feature stack)\n",
        "X, y, num_classes, class_names, sampling_rate, has_null = load_dataset('rwhar_3sbjs', include_null=True)\n",
        "# since the method returns features and labels separatley, we need to concat them\n",
        "data = np.concatenate((X, y[:, None]), axis=1)\n",
        "\n",
        "# define the train data to be the data of the first subject\n",
        "train_data = data[data[:, 0] == 0]\n",
        "# define the valid data to be the data of the second subject\n",
        "valid_data = data[data[:, 0] == 1]\n",
        "# define the test data to be the data of the third subject\n",
        "test_data = data[data[:, 0] == 2]\n",
        "\n",
        "# define the train_valid_data by concatenating the train and validation dataset \n",
        "train_valid_data = np.concatenate((train_data, valid_data), axis=0)\n",
        "\n",
        "print('\\nShape of the train, validation and test dataset:')\n",
        "print(train_data.shape, valid_data.shape, test_data.shape)\n",
        "print('\\nShape of the concatenated train_valid dataset:')\n",
        "print(train_valid_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzCPsMcd4koA"
      },
      "source": [
        "## 5.2. Define the hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_q8TpPal9BE"
      },
      "source": [
        "Before we go over talking about how to perform validation in Human Activtiy Recognition, we need to define our hyperparameters again. As you know from the previous notebook, it is common practice to track all your settings and parameters in a compiled `config` object. Due to fact that we will be using pre-implemented methods of the feature stack of the DL-ARC GitHub, we will now need to define a more complex `config` object. \n",
        "\n",
        "Within the next code block we defined a sample `config` object for you. It contains some parameters which you already know from previous notebooks, but also lots which you don't know. We will not cover all of them during this tutorial, but encourage you to check out the complete implementation of the DL-ARC. We also separated the parameters into two groups for you, once which you can play around with and ones which you should handle with care and rather leave as is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jjZYXFX6l9BF"
      },
      "outputs": [],
      "source": [
        "from misc.torchutils import seed_torch\n",
        "\n",
        "config = {\n",
        "    #### TRY AND CHANGE THESE PARAMETERS ####\n",
        "    # sliding window settings\n",
        "    'sw_length': 50,\n",
        "    'sw_unit': 'units',\n",
        "    'sampling_rate': 50,\n",
        "    'sw_overlap': 30,\n",
        "    # network settings\n",
        "    'nb_conv_blocks': 2,\n",
        "    'conv_block_type': 'normal',\n",
        "    'nb_filters': 64,\n",
        "    'filter_width': 11,\n",
        "    'nb_units_lstm': 128,\n",
        "    'nb_layers_lstm': 1,\n",
        "    'drop_prob': 0.5,\n",
        "    # training settings\n",
        "    'epochs': 10,\n",
        "    'valid_epoch': 'best',\n",
        "    'batch_size': 100,\n",
        "    'loss': 'cross_entropy',\n",
        "    'weighted': True,\n",
        "    'weights_init': 'xavier_uniform',\n",
        "    'optimizer': 'adam',\n",
        "    'lr': 1e-4,\n",
        "    'weight_decay': 1e-6,\n",
        "    'shuffling': True,\n",
        "    ### UP FROM HERE YOU SHOULD RATHER NOT CHANGE THESE ####\n",
        "    'no_lstm': False,\n",
        "    'batch_norm': False,\n",
        "    'dilation': 1,\n",
        "    'pooling': False,\n",
        "    'pool_type': 'max',\n",
        "    'pool_kernel_width': 2,\n",
        "    'reduce_layer': False,\n",
        "    'reduce_layer_output': 10,\n",
        "    'nb_classes': 8,\n",
        "    'seed': 1,\n",
        "    'gpu': 'cuda:0',\n",
        "    'verbose': False,\n",
        "    'print_freq': 10,\n",
        "    'save_gradient_plot': False,\n",
        "    'print_counts': False,\n",
        "    'adj_lr': False,\n",
        "    'adj_lr_patience': 5,\n",
        "    'early_stopping': False,\n",
        "    'es_patience': 5,\n",
        "    'save_test_preds': False\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0WRQj1dl9BF"
      },
      "source": [
        "## 5.3. Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhwdRETQ8t9D"
      },
      "source": [
        "Within the next segment we will explain the most prominent validation methods used in Human Activity Recognition. These are:\n",
        "\n",
        "- Train-Valid Split\n",
        "- k-Fold Cross-Validation\n",
        "- Cross-Participant Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQPUaRRE8AC9"
      },
      "source": [
        "### 5.3.1. Train-Valid Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8BS4Qf3l9BF"
      },
      "source": [
        "The train-valid split is one of the most basic validation method, which you  already did yourself. Instead of varying the validation set and getting a more holistic view, we define it to be a set part of the data. As mentioned above there are multiple ways how to do so. For simplicity purposes, we chose to use a subject-wise split. Within the next task you will be asked to train your network using the `train` data and obtain predictions on the `valid` data. We do not ask you to define the training loop again and allow you to use the built-in `train` function of the DL-ARC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOcMYLvTl9BF"
      },
      "source": [
        "#### Task 2: Implementing the train-valid split validation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsRp7hDNl9BF"
      },
      "source": [
        "1. As you already defined the train and valid dataset you can go ahead and apply a sliding window on top of both datasets. You can use the predefined method `apply_sliding_window()`, which is part of the DL-ARC pipeline, to do so. It is already be imported for you. We will give you hints on what to pass the method. (`lines 22-30`)\n",
        "2. (*Optional*) Omit the first feature column (subject_identifier) from the train and validation dataset. (`lines 32-34`)\n",
        "3. Within the `config` object, set the parameters `window_size` and `nb_channels` accordingly. (`lines 36-40`)\n",
        "4. Define the `DeepConvLSTM` object. It is already imported for you. Also define the `optimizer` being the [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and `criterion` being the [Cross-Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (`lines 42-48`)\n",
        "5. Convert the feature columns of the train and validation to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 50-52`)\n",
        "6. Use both datasets to run the `train()` function. (`lines 54-55`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "61uZSoSdl9BG",
        "scrolled": true,
        "outputId": "542922ec-307f-4a75-a32d-415c079e8612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(221621, 5) (208835, 5)\n",
            "(6331, 50, 4) (6331,)\n",
            "(5966, 50, 4) (5966,)\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0900, 0.8437, 6.3821, 0.8813, 0.9044, 0.8428, 0.8621, 0.8668])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.9435 Train Acc (M): 0.1444 Train Prc (M): 0.2567 Train Rcl (M): 0.2814 Train F1 (M): 0.2389 Train Acc (W): 0.1586 Train Prc (W): 0.2824 Train Rcl (W): 0.2808 Train F1 (W): 0.2609 \n",
            "Valid Loss: 1.3180 Valid Acc (M): 0.3664 Valid Prc (M): 0.4718 Valid Rcl (M): 0.4792 Valid F1 (M): 0.4558 Valid Acc (W): 0.4299 Valid Prc (W): 0.5508 Valid Rcl (W): 0.5598 Valid F1 (W): 0.5326\n",
            "Performance improved... (0.0->0.4557867431186733)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 1.2139 Train Acc (M): 0.4159 Train Prc (M): 0.5290 Train Rcl (M): 0.5598 Train F1 (M): 0.5392 Train Acc (W): 0.4421 Train Prc (W): 0.5611 Train Rcl (W): 0.5671 Train F1 (W): 0.5624 \n",
            "Valid Loss: 1.1005 Valid Acc (M): 0.4047 Valid Prc (M): 0.4823 Valid Rcl (M): 0.5850 Valid F1 (M): 0.4726 Valid Acc (W): 0.4594 Valid Prc (W): 0.5433 Valid Rcl (W): 0.5572 Valid F1 (W): 0.5246\n",
            "Performance improved... (0.4557867431186733->0.4726484534463617)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.8280 Train Acc (M): 0.5825 Train Prc (M): 0.6915 Train Rcl (M): 0.7138 Train F1 (M): 0.7002 Train Acc (W): 0.5889 Train Prc (W): 0.7034 Train Rcl (W): 0.7007 Train F1 (W): 0.7013 \n",
            "Valid Loss: 1.2298 Valid Acc (M): 0.4123 Valid Prc (M): 0.5255 Valid Rcl (M): 0.5950 Valid F1 (M): 0.4794 Valid Acc (W): 0.4674 Valid Prc (W): 0.5927 Valid Rcl (W): 0.5669 Valid F1 (W): 0.5313\n",
            "Performance improved... (0.4726484534463617->0.47935257037844253)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6750 Train Acc (M): 0.6787 Train Prc (M): 0.7769 Train Rcl (M): 0.7879 Train F1 (M): 0.7816 Train Acc (W): 0.6637 Train Prc (W): 0.7692 Train Rcl (W): 0.7708 Train F1 (W): 0.7694 \n",
            "Valid Loss: 1.1638 Valid Acc (M): 0.4303 Valid Prc (M): 0.5356 Valid Rcl (M): 0.6126 Valid F1 (M): 0.5004 Valid Acc (W): 0.4881 Valid Prc (W): 0.5999 Valid Rcl (W): 0.5900 Valid F1 (W): 0.5551\n",
            "Performance improved... (0.47935257037844253->0.5004089260171903)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5901 Train Acc (M): 0.7268 Train Prc (M): 0.8233 Train Rcl (M): 0.8242 Train F1 (M): 0.8231 Train Acc (W): 0.7082 Train Prc (W): 0.8105 Train Rcl (W): 0.8114 Train F1 (W): 0.8102 \n",
            "Valid Loss: 1.2146 Valid Acc (M): 0.4248 Valid Prc (M): 0.5585 Valid Rcl (M): 0.6039 Valid F1 (M): 0.4926 Valid Acc (W): 0.4815 Valid Prc (W): 0.6276 Valid Rcl (W): 0.5771 Valid F1 (W): 0.5458\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5464 Train Acc (M): 0.7443 Train Prc (M): 0.8391 Train Rcl (M): 0.8381 Train F1 (M): 0.8378 Train Acc (W): 0.7264 Train Prc (W): 0.8268 Train Rcl (W): 0.8272 Train F1 (W): 0.8261 \n",
            "Valid Loss: 1.2482 Valid Acc (M): 0.4328 Valid Prc (M): 0.5632 Valid Rcl (M): 0.6138 Valid F1 (M): 0.5042 Valid Acc (W): 0.4893 Valid Prc (W): 0.6282 Valid Rcl (W): 0.5892 Valid F1 (W): 0.5569\n",
            "Performance improved... (0.5004089260171903->0.5042497514161205)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5096 Train Acc (M): 0.7633 Train Prc (M): 0.8569 Train Rcl (M): 0.8538 Train F1 (M): 0.8541 Train Acc (W): 0.7480 Train Prc (W): 0.8459 Train Rcl (W): 0.8452 Train F1 (W): 0.8442 \n",
            "Valid Loss: 1.2617 Valid Acc (M): 0.4390 Valid Prc (M): 0.6039 Valid Rcl (M): 0.6227 Valid F1 (M): 0.5132 Valid Acc (W): 0.4947 Valid Prc (W): 0.6734 Valid Rcl (W): 0.5974 Valid F1 (W): 0.5643\n",
            "Performance improved... (0.5042497514161205->0.5131747317810611)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.4819 Train Acc (M): 0.7723 Train Prc (M): 0.8649 Train Rcl (M): 0.8597 Train F1 (M): 0.8611 Train Acc (W): 0.7580 Train Prc (W): 0.8536 Train Rcl (W): 0.8528 Train F1 (W): 0.8520 \n",
            "Valid Loss: 1.3994 Valid Acc (M): 0.4131 Valid Prc (M): 0.5369 Valid Rcl (M): 0.5889 Valid F1 (M): 0.4769 Valid Acc (W): 0.4683 Valid Prc (W): 0.6031 Valid Rcl (W): 0.5592 Valid F1 (W): 0.5283\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4695 Train Acc (M): 0.7726 Train Prc (M): 0.8624 Train Rcl (M): 0.8613 Train F1 (M): 0.8612 Train Acc (W): 0.7600 Train Prc (W): 0.8537 Train Rcl (W): 0.8539 Train F1 (W): 0.8531 \n",
            "Valid Loss: 1.4439 Valid Acc (M): 0.4077 Valid Prc (M): 0.5412 Valid Rcl (M): 0.5866 Valid F1 (M): 0.4705 Valid Acc (W): 0.4608 Valid Prc (W): 0.6072 Valid Rcl (W): 0.5546 Valid F1 (W): 0.5189\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4432 Train Acc (M): 0.7838 Train Prc (M): 0.8737 Train Rcl (M): 0.8680 Train F1 (M): 0.8697 Train Acc (W): 0.7689 Train Prc (W): 0.8621 Train Rcl (W): 0.8612 Train F1 (W): 0.8605 \n",
            "Valid Loss: 1.4573 Valid Acc (M): 0.4024 Valid Prc (M): 0.5411 Valid Rcl (M): 0.5819 Valid F1 (M): 0.4644 Valid Acc (W): 0.4546 Valid Prc (W): 0.6078 Valid Rcl (W): 0.5488 Valid F1 (W): 0.5117\n",
            "\n",
            "VALIDATION RESULTS: \n",
            "\n",
            "Avg. Accuracy: 0.4390331000950286\n",
            "Avg. Precision: 0.6039021194259713\n",
            "Avg. Recall: 0.6227004072777095\n",
            "Avg. F1: 0.5131747317810611\n",
            "\n",
            "VALIDATION RESULTS (PER CLASS): \n",
            "\n",
            "Accuracy:\n",
            "   climbing_down: 0.27111984282907664\n",
            "   climbing_up: 0.06481481481481481\n",
            "   jumping: 0.12087912087912088\n",
            "   lying: 0.9819616685456595\n",
            "   running: 0.0034129692832764505\n",
            "   sitting: 0.9052083333333333\n",
            "   standing: 0.8575883575883576\n",
            "   walking: 0.30727969348659\n",
            "\n",
            "Precision:\n",
            "   climbing_down: 0.336038961038961\n",
            "   climbing_up: 0.5632183908045977\n",
            "   jumping: 0.12143514259429623\n",
            "   lying: 1.0\n",
            "   running: 0.5\n",
            "   sitting: 0.9176346356916578\n",
            "   standing: 0.9085903083700441\n",
            "   walking: 0.48429951690821255\n",
            "\n",
            "Recall:\n",
            "   climbing_down: 0.5839210155148096\n",
            "   climbing_up: 0.06824512534818941\n",
            "   jumping: 0.9635036496350365\n",
            "   lying: 0.9819616685456595\n",
            "   running: 0.003424657534246575\n",
            "   sitting: 0.9852607709750567\n",
            "   standing: 0.9385665529010239\n",
            "   walking: 0.45671981776765375\n",
            "\n",
            "F1:\n",
            "   climbing_down: 0.4265842349304482\n",
            "   climbing_up: 0.12173913043478261\n",
            "   jumping: 0.21568627450980393\n",
            "   lying: 0.9908987485779295\n",
            "   running: 0.006802721088435374\n",
            "   sitting: 0.9502460360852926\n",
            "   standing: 0.923335198656967\n",
            "   walking: 0.47010550996483\n",
            "\n",
            "GENERALIZATION GAP ANALYSIS: \n",
            "\n",
            "Train-Val-Accuracy Difference: -0.3731012004512052\n",
            "Train-Val-Precision Difference: -0.48139656699837463\n",
            "Train-Val-Recall Difference: -0.49970213151670806\n",
            "Train-Val-F1 Difference: -0.3906490157759138\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
        "from model.train import train\n",
        "from model.DeepConvLSTM import DeepConvLSTM\n",
        "from data_processing.sliding_window import apply_sliding_window\n",
        "from misc.torchutils import seed_torch\n",
        "\n",
        "\n",
        "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
        "seed_torch(config['seed'])\n",
        "\n",
        "# needed for saving results\n",
        "log_date = time.strftime('%Y%m%d')\n",
        "log_timestamp = time.strftime('%H%M%S')\n",
        "\n",
        "print(train_data.shape, valid_data.shape)\n",
        "\n",
        "# apply the sliding window on top of both the train and validation data; use the \"apply_sliding_window\" function\n",
        "# found in data_processing.sliding_window\n",
        "X_train, y_train = apply_sliding_window(train_data[:, :-1], train_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "X_valid, y_valid = apply_sliding_window(valid_data[:, :-1], valid_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
        "\n",
        "print(X_valid.shape, y_valid.shape)\n",
        "\n",
        "# (optional) omit the first feature column (subject_identifier) from the train and validation dataset\n",
        "# you can do it if you want to as it is not a useful feature\n",
        "X_train, X_valid = X_train[:, :, 1:], X_valid[:, :, 1:]\n",
        "\n",
        "# within the config file, set the parameters 'window_size' and 'nb_channels' accordingly\n",
        "# window_size = size of the sliding window in units\n",
        "# nb_channels = number of feature channels\n",
        "config['window_size'] = X_train.shape[1]\n",
        "config['nb_channels'] = X_train.shape[2]\n",
        "\n",
        "# define the network to be a DeepConvLSTM object; can be imported from model.DeepConvLSTM\n",
        "# pass it the config object\n",
        "net = DeepConvLSTM(config=config)\n",
        "\n",
        "# defines the loss and optimizer\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "\n",
        "# convert the features of the train and validation to float32 and labels to uint8 for GPU compatibility \n",
        "X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
        "X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
        "\n",
        "# feed the datasets into the train function; can be imported from model.train\n",
        "train_valid_net,_, val_output, train_output = train(X_train, y_train, X_valid, y_valid, network=net, optimizer=opt, loss=loss, config=config, log_date=log_date, log_timestamp=log_timestamp)\n",
        "\n",
        "# the next bit prints out your results if you did everything correctly\n",
        "cls = np.array(range(config['nb_classes']))\n",
        "\n",
        "print('\\nVALIDATION RESULTS: ')\n",
        "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "print(\"Avg. Precision: {0}\".format(precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "print(\"Avg. Recall: {0}\".format(recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "print(\"Avg. F1: {0}\".format(f1_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "\n",
        "print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
        "print(\"\\nAccuracy:\")\n",
        "for i, rslt in enumerate(jaccard_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "print(\"\\nPrecision:\")\n",
        "for i, rslt in enumerate(precision_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "print(\"\\nRecall:\")\n",
        "for i, rslt in enumerate(recall_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "print(\"\\nF1:\")\n",
        "for i, rslt in enumerate(f1_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "\n",
        "print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
        "print(\"\\nTrain-Val-Accuracy Difference: {0}\".format(jaccard_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                                  jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "print(\"Train-Val-Precision Difference: {0}\".format(precision_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                                   precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "print(\"Train-Val-Recall Difference: {0}\".format(recall_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                                recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "print(\"Train-Val-F1 Difference: {0}\".format(f1_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                            f1_score(val_output[:, 1], val_output[:, 0], average='macro')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BepnQk8l9BH"
      },
      "source": [
        "### 5.3.2. K-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OlOGi55l9BJ"
      },
      "source": [
        "The k-fold cross-validation is the most popular form of cross-validation. Instead of only splitting our data once into a train and validation dataset, like we did in the previous validation method, we take the average of k different train-valid splits. To do so we take our concatenated version of the train and validation set and split it into k equal-sized chunks of data. A so-called fold is now that we train our network using all but one of these chunks of data and validate it using the chunk we excluded (thus being unseen data). The process is repeated k-times, i.e. k-folds, so that each chunk of data is the validation dataset exactly once. Note that with each fold, the network needs to be reinitialized, i.e. trained from scratch, to ensure that it is not predicting already seen data.\n",
        "\n",
        "\n",
        "**Note:** It is recommended to use stratified k-fold cross-validation, i.e. each of the k chunks of data has the same distribution of labels as the original full dataset. This avoids the risk, especially for unbalanced datasets, of having certain labels missing within the train dataset, which would cause the validation process to break. Nevertheless, as also stated above, stratification requires shuffeling and thus one should always first apply the sliding window before applying the split.\n",
        "\n",
        "The next task will lead you through the implementation of the k-fold cross-validation loop. In order to chunk your data and also apply stratification, we recommend you to use the scikit-learn helper object for stratified k-fold cross-validation called `StratifiedKFold`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sK2SCNYl9BJ"
      },
      "source": [
        "#### Task 3: Implementing the k-fold CV loop "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iirq5yFll9BK"
      },
      "source": [
        "1. Define the scikit-learn helper object for stratified k-fold cross-validation called `StratifiedKFold`. It is already imported for you. We will also give you hints what to pass it as arguments. (`lines 14-16`)\n",
        "2. Apply the `apply_sliding_window()` function on top of the `train_valid_data` object which you previously defined. (`lines 20-24`)\n",
        "3. (*Optional*) Omit the first feature column (subject_identifier) from the `train_valid_data` dataset. (`lines 26-28`)\n",
        "4. Define the k-fold loop; use the `split()` function of the `StratifiedKFold` object to obtain indeces to split the `train_valid_data` (`lines 42-49`)\n",
        "5. Within the `config` object, set the parameters `window_size` and `nb_channels` accordingly. (`lines 51-55`)\n",
        "6. Define the `DeepConvLSTM` object. It is already imported for you. Also define the `optimizer` being the [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and `criterion` being the [Cross-Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (`lines 57-63`)\n",
        "7. Convert the feature columns of the train and validation to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 65-67`)\n",
        "8. Use both datasets to run the `train()` function. (`lines 69-70`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wnh-tBGAl9BK",
        "scrolled": true,
        "outputId": "d0a3c6f2-c8c3-4e62-f0c9-1d9b9cf92c1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(430456, 5)\n",
            "(12297, 50, 4) (12297,)\n",
            "\n",
            "Fold 1/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0716, 0.9284, 5.8867, 0.8608, 0.8778, 0.8440, 0.8555, 0.8582])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.6153 Train Acc (M): 0.2364 Train Prc (M): 0.3679 Train Rcl (M): 0.3789 Train F1 (M): 0.3517 Train Acc (W): 0.2644 Train Prc (W): 0.4125 Train Rcl (W): 0.3795 Train F1 (W): 0.3894 \n",
            "Valid Loss: 0.8603 Valid Acc (M): 0.5730 Valid Prc (M): 0.7095 Valid Rcl (M): 0.7132 Valid F1 (M): 0.6857 Valid Acc (W): 0.6279 Valid Prc (W): 0.7684 Valid Rcl (W): 0.7455 Valid F1 (W): 0.7350\n",
            "Performance improved... (0.0->0.6857183921779146)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8493 Train Acc (M): 0.5405 Train Prc (M): 0.6516 Train Rcl (M): 0.6839 Train F1 (M): 0.6585 Train Acc (W): 0.5794 Train Prc (W): 0.6972 Train Rcl (W): 0.6897 Train F1 (W): 0.6903 \n",
            "Valid Loss: 0.6623 Valid Acc (M): 0.6013 Valid Prc (M): 0.7380 Valid Rcl (M): 0.7647 Valid F1 (M): 0.7202 Valid Acc (W): 0.6414 Valid Prc (W): 0.7850 Valid Rcl (W): 0.7553 Valid F1 (W): 0.7524\n",
            "Performance improved... (0.6857183921779146->0.7202112109448073)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.6909 Train Acc (M): 0.6233 Train Prc (M): 0.7244 Train Rcl (M): 0.7564 Train F1 (M): 0.7349 Train Acc (W): 0.6483 Train Prc (W): 0.7550 Train Rcl (W): 0.7514 Train F1 (W): 0.7515 \n",
            "Valid Loss: 0.5752 Valid Acc (M): 0.6900 Valid Prc (M): 0.7848 Valid Rcl (M): 0.7941 Valid F1 (M): 0.7870 Valid Acc (W): 0.6847 Valid Prc (W): 0.7846 Valid Rcl (W): 0.7837 Valid F1 (W): 0.7817\n",
            "Performance improved... (0.7202112109448073->0.7869505816689656)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6054 Train Acc (M): 0.6757 Train Prc (M): 0.7686 Train Rcl (M): 0.7884 Train F1 (M): 0.7769 Train Acc (W): 0.6820 Train Prc (W): 0.7791 Train Rcl (W): 0.7809 Train F1 (W): 0.7793 \n",
            "Valid Loss: 0.5225 Valid Acc (M): 0.7472 Valid Prc (M): 0.8434 Valid Rcl (M): 0.8434 Valid F1 (M): 0.8388 Valid Acc (W): 0.7445 Valid Prc (W): 0.8420 Valid Rcl (W): 0.8407 Valid F1 (W): 0.8367\n",
            "Performance improved... (0.7869505816689656->0.8387875177291945)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5753 Train Acc (M): 0.7006 Train Prc (M): 0.7918 Train Rcl (M): 0.8029 Train F1 (M): 0.7966 Train Acc (W): 0.6986 Train Prc (W): 0.7934 Train Rcl (W): 0.7959 Train F1 (W): 0.7941 \n",
            "Valid Loss: 0.5149 Valid Acc (M): 0.7430 Valid Prc (M): 0.8398 Valid Rcl (M): 0.8362 Valid F1 (M): 0.8333 Valid Acc (W): 0.7364 Valid Prc (W): 0.8349 Valid Rcl (W): 0.8325 Valid F1 (W): 0.8286\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5466 Train Acc (M): 0.7124 Train Prc (M): 0.8037 Train Rcl (M): 0.8089 Train F1 (M): 0.8058 Train Acc (W): 0.7058 Train Prc (W): 0.8002 Train Rcl (W): 0.8021 Train F1 (W): 0.8007 \n",
            "Valid Loss: 0.4966 Valid Acc (M): 0.7412 Valid Prc (M): 0.8322 Valid Rcl (M): 0.8352 Valid F1 (M): 0.8312 Valid Acc (W): 0.7345 Valid Prc (W): 0.8289 Valid Rcl (W): 0.8293 Valid F1 (W): 0.8264\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5201 Train Acc (M): 0.7240 Train Prc (M): 0.8143 Train Rcl (M): 0.8188 Train F1 (M): 0.8159 Train Acc (W): 0.7172 Train Prc (W): 0.8104 Train Rcl (W): 0.8127 Train F1 (W): 0.8109 \n",
            "Valid Loss: 0.4865 Valid Acc (M): 0.7426 Valid Prc (M): 0.8365 Valid Rcl (M): 0.8366 Valid F1 (M): 0.8318 Valid Acc (W): 0.7362 Valid Prc (W): 0.8338 Valid Rcl (W): 0.8309 Valid F1 (W): 0.8272\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5046 Train Acc (M): 0.7322 Train Prc (M): 0.8225 Train Rcl (M): 0.8276 Train F1 (M): 0.8243 Train Acc (W): 0.7284 Train Prc (W): 0.8209 Train Rcl (W): 0.8229 Train F1 (W): 0.8212 \n",
            "Valid Loss: 0.4740 Valid Acc (M): 0.7472 Valid Prc (M): 0.8372 Valid Rcl (M): 0.8399 Valid F1 (M): 0.8368 Valid Acc (W): 0.7408 Valid Prc (W): 0.8349 Valid Rcl (W): 0.8333 Valid F1 (W): 0.8322\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4848 Train Acc (M): 0.7446 Train Prc (M): 0.8341 Train Rcl (M): 0.8362 Train F1 (M): 0.8344 Train Acc (W): 0.7381 Train Prc (W): 0.8296 Train Rcl (W): 0.8317 Train F1 (W): 0.8298 \n",
            "Valid Loss: 0.4586 Valid Acc (M): 0.7619 Valid Prc (M): 0.8503 Valid Rcl (M): 0.8496 Valid F1 (M): 0.8486 Valid Acc (W): 0.7526 Valid Prc (W): 0.8443 Valid Rcl (W): 0.8439 Valid F1 (W): 0.8426\n",
            "Performance improved... (0.8387875177291945->0.8486086906516273)\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4733 Train Acc (M): 0.7519 Train Prc (M): 0.8410 Train Rcl (M): 0.8420 Train F1 (M): 0.8407 Train Acc (W): 0.7437 Train Prc (W): 0.8353 Train Rcl (W): 0.8370 Train F1 (W): 0.8353 \n",
            "Valid Loss: 0.4433 Valid Acc (M): 0.7776 Valid Prc (M): 0.8641 Valid Rcl (M): 0.8588 Valid F1 (M): 0.8607 Valid Acc (W): 0.7653 Valid Prc (W): 0.8539 Valid Rcl (W): 0.8545 Valid F1 (W): 0.8534\n",
            "Performance improved... (0.8486086906516273->0.8606992632458775)\n",
            "\n",
            "Fold 2/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0707, 0.9284, 5.9119, 0.8608, 0.8778, 0.8440, 0.8555, 0.8582])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.6125 Train Acc (M): 0.2291 Train Prc (M): 0.3803 Train Rcl (M): 0.3823 Train F1 (M): 0.3437 Train Acc (W): 0.2531 Train Prc (W): 0.4246 Train Rcl (W): 0.3589 Train F1 (W): 0.3752 \n",
            "Valid Loss: 0.8730 Valid Acc (M): 0.5542 Valid Prc (M): 0.6865 Valid Rcl (M): 0.7127 Valid F1 (M): 0.6776 Valid Acc (W): 0.5902 Valid Prc (W): 0.7331 Valid Rcl (W): 0.7138 Valid F1 (W): 0.7066\n",
            "Performance improved... (0.0->0.6775661239582198)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8435 Train Acc (M): 0.5442 Train Prc (M): 0.6548 Train Rcl (M): 0.6905 Train F1 (M): 0.6638 Train Acc (W): 0.5760 Train Prc (W): 0.6937 Train Rcl (W): 0.6874 Train F1 (W): 0.6880 \n",
            "Valid Loss: 0.6399 Valid Acc (M): 0.6441 Valid Prc (M): 0.7499 Valid Rcl (M): 0.7884 Valid F1 (M): 0.7601 Valid Acc (W): 0.6683 Valid Prc (W): 0.7820 Valid Rcl (W): 0.7789 Valid F1 (W): 0.7768\n",
            "Performance improved... (0.6775661239582198->0.760110822160032)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.6737 Train Acc (M): 0.6390 Train Prc (M): 0.7391 Train Rcl (M): 0.7660 Train F1 (M): 0.7492 Train Acc (W): 0.6572 Train Prc (W): 0.7610 Train Rcl (W): 0.7626 Train F1 (W): 0.7604 \n",
            "Valid Loss: 0.5426 Valid Acc (M): 0.7267 Valid Prc (M): 0.8200 Valid Rcl (M): 0.8228 Valid F1 (M): 0.8188 Valid Acc (W): 0.7232 Valid Prc (W): 0.8191 Valid Rcl (W): 0.8179 Valid F1 (W): 0.8161\n",
            "Performance improved... (0.760110822160032->0.8188046650270286)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.5987 Train Acc (M): 0.6886 Train Prc (M): 0.7829 Train Rcl (M): 0.7945 Train F1 (M): 0.7876 Train Acc (W): 0.6890 Train Prc (W): 0.7857 Train Rcl (W): 0.7887 Train F1 (W): 0.7864 \n",
            "Valid Loss: 0.5161 Valid Acc (M): 0.7237 Valid Prc (M): 0.8171 Valid Rcl (M): 0.8263 Valid F1 (M): 0.8207 Valid Acc (W): 0.7285 Valid Prc (W): 0.8231 Valid Rcl (W): 0.8244 Valid F1 (W): 0.8229\n",
            "Performance improved... (0.8188046650270286->0.8207138694976168)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5653 Train Acc (M): 0.7044 Train Prc (M): 0.7963 Train Rcl (M): 0.8051 Train F1 (M): 0.7999 Train Acc (W): 0.7002 Train Prc (W): 0.7953 Train Rcl (W): 0.7985 Train F1 (W): 0.7962 \n",
            "Valid Loss: 0.4814 Valid Acc (M): 0.7423 Valid Prc (M): 0.8347 Valid Rcl (M): 0.8334 Valid F1 (M): 0.8311 Valid Acc (W): 0.7367 Valid Prc (W): 0.8302 Valid Rcl (W): 0.8301 Valid F1 (W): 0.8273\n",
            "Performance improved... (0.8207138694976168->0.83113532747942)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5384 Train Acc (M): 0.7175 Train Prc (M): 0.8096 Train Rcl (M): 0.8154 Train F1 (M): 0.8118 Train Acc (W): 0.7131 Train Prc (W): 0.8074 Train Rcl (W): 0.8102 Train F1 (W): 0.8081 \n",
            "Valid Loss: 0.4725 Valid Acc (M): 0.7496 Valid Prc (M): 0.8385 Valid Rcl (M): 0.8410 Valid F1 (M): 0.8388 Valid Acc (W): 0.7437 Valid Prc (W): 0.8348 Valid Rcl (W): 0.8366 Valid F1 (W): 0.8347\n",
            "Performance improved... (0.83113532747942->0.8387757938634102)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5157 Train Acc (M): 0.7322 Train Prc (M): 0.8231 Train Rcl (M): 0.8256 Train F1 (M): 0.8235 Train Acc (W): 0.7250 Train Prc (W): 0.8180 Train Rcl (W): 0.8205 Train F1 (W): 0.8183 \n",
            "Valid Loss: 0.4504 Valid Acc (M): 0.7572 Valid Prc (M): 0.8507 Valid Rcl (M): 0.8443 Valid F1 (M): 0.8451 Valid Acc (W): 0.7519 Valid Prc (W): 0.8441 Valid Rcl (W): 0.8439 Valid F1 (W): 0.8414\n",
            "Performance improved... (0.8387757938634102->0.8451314383373938)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5026 Train Acc (M): 0.7411 Train Prc (M): 0.8312 Train Rcl (M): 0.8325 Train F1 (M): 0.8310 Train Acc (W): 0.7323 Train Prc (W): 0.8249 Train Rcl (W): 0.8271 Train F1 (W): 0.8250 \n",
            "Valid Loss: 0.4413 Valid Acc (M): 0.7712 Valid Prc (M): 0.8586 Valid Rcl (M): 0.8553 Valid F1 (M): 0.8561 Valid Acc (W): 0.7627 Valid Prc (W): 0.8518 Valid Rcl (W): 0.8512 Valid F1 (W): 0.8506\n",
            "Performance improved... (0.8451314383373938->0.8560758132022044)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4853 Train Acc (M): 0.7457 Train Prc (M): 0.8353 Train Rcl (M): 0.8361 Train F1 (M): 0.8349 Train Acc (W): 0.7379 Train Prc (W): 0.8294 Train Rcl (W): 0.8317 Train F1 (W): 0.8296 \n",
            "Valid Loss: 0.4230 Valid Acc (M): 0.7816 Valid Prc (M): 0.8681 Valid Rcl (M): 0.8638 Valid F1 (M): 0.8641 Valid Acc (W): 0.7739 Valid Prc (W): 0.8615 Valid Rcl (W): 0.8610 Valid F1 (W): 0.8593\n",
            "Performance improved... (0.8560758132022044->0.8641109560016935)\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4732 Train Acc (M): 0.7523 Train Prc (M): 0.8419 Train Rcl (M): 0.8404 Train F1 (M): 0.8402 Train Acc (W): 0.7416 Train Prc (W): 0.8334 Train Rcl (W): 0.8353 Train F1 (W): 0.8333 \n",
            "Valid Loss: 0.4167 Valid Acc (M): 0.7736 Valid Prc (M): 0.8784 Valid Rcl (M): 0.8541 Valid F1 (M): 0.8559 Valid Acc (W): 0.7625 Valid Prc (W): 0.8652 Valid Rcl (W): 0.8537 Valid F1 (W): 0.8494\n",
            "\n",
            "Fold 3/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0707, 0.9284, 5.8867, 0.8614, 0.8778, 0.8440, 0.8555, 0.8582])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.6749 Train Acc (M): 0.2206 Train Prc (M): 0.3541 Train Rcl (M): 0.3599 Train F1 (M): 0.3385 Train Acc (W): 0.2437 Train Prc (W): 0.3948 Train Rcl (W): 0.3576 Train F1 (W): 0.3701 \n",
            "Valid Loss: 0.8718 Valid Acc (M): 0.5902 Valid Prc (M): 0.7315 Valid Rcl (M): 0.7404 Valid F1 (M): 0.7016 Valid Acc (W): 0.6230 Valid Prc (W): 0.7730 Valid Rcl (W): 0.7415 Valid F1 (W): 0.7251\n",
            "Performance improved... (0.0->0.7015846671051329)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8611 Train Acc (M): 0.5228 Train Prc (M): 0.6404 Train Rcl (M): 0.6711 Train F1 (M): 0.6434 Train Acc (W): 0.5649 Train Prc (W): 0.6916 Train Rcl (W): 0.6761 Train F1 (W): 0.6798 \n",
            "Valid Loss: 0.6272 Valid Acc (M): 0.6195 Valid Prc (M): 0.7383 Valid Rcl (M): 0.7636 Valid F1 (M): 0.7332 Valid Acc (W): 0.6498 Valid Prc (W): 0.7745 Valid Rcl (W): 0.7577 Valid F1 (W): 0.7548\n",
            "Performance improved... (0.7015846671051329->0.733155500227206)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.6838 Train Acc (M): 0.6156 Train Prc (M): 0.7195 Train Rcl (M): 0.7500 Train F1 (M): 0.7292 Train Acc (W): 0.6461 Train Prc (W): 0.7541 Train Rcl (W): 0.7507 Train F1 (W): 0.7508 \n",
            "Valid Loss: 0.5700 Valid Acc (M): 0.6936 Valid Prc (M): 0.7921 Valid Rcl (M): 0.7983 Valid F1 (M): 0.7931 Valid Acc (W): 0.6970 Valid Prc (W): 0.7987 Valid Rcl (W): 0.7935 Valid F1 (W): 0.7941\n",
            "Performance improved... (0.733155500227206->0.7931439867826464)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6178 Train Acc (M): 0.6633 Train Prc (M): 0.7610 Train Rcl (M): 0.7797 Train F1 (M): 0.7685 Train Acc (W): 0.6756 Train Prc (W): 0.7752 Train Rcl (W): 0.7768 Train F1 (W): 0.7751 \n",
            "Valid Loss: 0.5352 Valid Acc (M): 0.7103 Valid Prc (M): 0.8027 Valid Rcl (M): 0.8143 Valid F1 (M): 0.8077 Valid Acc (W): 0.7118 Valid Prc (W): 0.8090 Valid Rcl (W): 0.8073 Valid F1 (W): 0.8077\n",
            "Performance improved... (0.7931439867826464->0.8076586232913379)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5730 Train Acc (M): 0.6972 Train Prc (M): 0.7903 Train Rcl (M): 0.7996 Train F1 (M): 0.7940 Train Acc (W): 0.6955 Train Prc (W): 0.7913 Train Rcl (W): 0.7933 Train F1 (W): 0.7915 \n",
            "Valid Loss: 0.5107 Valid Acc (M): 0.7315 Valid Prc (M): 0.8232 Valid Rcl (M): 0.8255 Valid F1 (M): 0.8234 Valid Acc (W): 0.7247 Valid Prc (W): 0.8200 Valid Rcl (W): 0.8195 Valid F1 (W): 0.8188\n",
            "Performance improved... (0.8076586232913379->0.8234427689807073)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5450 Train Acc (M): 0.7184 Train Prc (M): 0.8110 Train Rcl (M): 0.8151 Train F1 (M): 0.8122 Train Acc (W): 0.7121 Train Prc (W): 0.8070 Train Rcl (W): 0.8093 Train F1 (W): 0.8073 \n",
            "Valid Loss: 0.4904 Valid Acc (M): 0.7378 Valid Prc (M): 0.8321 Valid Rcl (M): 0.8280 Valid F1 (M): 0.8265 Valid Acc (W): 0.7287 Valid Prc (W): 0.8242 Valid Rcl (W): 0.8252 Valid F1 (W): 0.8210\n",
            "Performance improved... (0.8234427689807073->0.8264971896627228)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5193 Train Acc (M): 0.7254 Train Prc (M): 0.8184 Train Rcl (M): 0.8209 Train F1 (M): 0.8186 Train Acc (W): 0.7204 Train Prc (W): 0.8146 Train Rcl (W): 0.8165 Train F1 (W): 0.8145 \n",
            "Valid Loss: 0.4774 Valid Acc (M): 0.7460 Valid Prc (M): 0.8419 Valid Rcl (M): 0.8358 Valid F1 (M): 0.8348 Valid Acc (W): 0.7371 Valid Prc (W): 0.8340 Valid Rcl (W): 0.8333 Valid F1 (W): 0.8294\n",
            "Performance improved... (0.8264971896627228->0.8348355012143067)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5014 Train Acc (M): 0.7364 Train Prc (M): 0.8282 Train Rcl (M): 0.8265 Train F1 (M): 0.8263 Train Acc (W): 0.7264 Train Prc (W): 0.8196 Train Rcl (W): 0.8218 Train F1 (W): 0.8196 \n",
            "Valid Loss: 0.4652 Valid Acc (M): 0.7492 Valid Prc (M): 0.8390 Valid Rcl (M): 0.8380 Valid F1 (M): 0.8376 Valid Acc (W): 0.7404 Valid Prc (W): 0.8324 Valid Rcl (W): 0.8341 Valid F1 (W): 0.8323\n",
            "Performance improved... (0.8348355012143067->0.8376095643401917)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4840 Train Acc (M): 0.7446 Train Prc (M): 0.8344 Train Rcl (M): 0.8368 Train F1 (M): 0.8346 Train Acc (W): 0.7377 Train Prc (W): 0.8298 Train Rcl (W): 0.8318 Train F1 (W): 0.8297 \n",
            "Valid Loss: 0.4566 Valid Acc (M): 0.7575 Valid Prc (M): 0.8479 Valid Rcl (M): 0.8451 Valid F1 (M): 0.8455 Valid Acc (W): 0.7486 Valid Prc (W): 0.8416 Valid Rcl (W): 0.8407 Valid F1 (W): 0.8400\n",
            "Performance improved... (0.8376095643401917->0.845479826170737)\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4696 Train Acc (M): 0.7552 Train Prc (M): 0.8443 Train Rcl (M): 0.8435 Train F1 (M): 0.8429 Train Acc (W): 0.7466 Train Prc (W): 0.8374 Train Rcl (W): 0.8390 Train F1 (W): 0.8371 \n",
            "Valid Loss: 0.4503 Valid Acc (M): 0.7577 Valid Prc (M): 0.8596 Valid Rcl (M): 0.8428 Valid F1 (M): 0.8428 Valid Acc (W): 0.7460 Valid Prc (W): 0.8469 Valid Rcl (W): 0.8423 Valid F1 (W): 0.8362\n",
            "\n",
            "Fold 4/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0707, 0.9284, 5.8867, 0.8614, 0.8778, 0.8440, 0.8550, 0.8587])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.5964 Train Acc (M): 0.2430 Train Prc (M): 0.3751 Train Rcl (M): 0.3865 Train F1 (M): 0.3518 Train Acc (W): 0.2728 Train Prc (W): 0.4215 Train Rcl (W): 0.3838 Train F1 (W): 0.3905 \n",
            "Valid Loss: 0.8927 Valid Acc (M): 0.6254 Valid Prc (M): 0.7563 Valid Rcl (M): 0.7312 Valid F1 (M): 0.7372 Valid Acc (W): 0.6564 Valid Prc (W): 0.7701 Valid Rcl (W): 0.7602 Valid F1 (W): 0.7590\n",
            "Performance improved... (0.0->0.7372136852890744)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.9185 Train Acc (M): 0.5142 Train Prc (M): 0.6268 Train Rcl (M): 0.6549 Train F1 (M): 0.6333 Train Acc (W): 0.5512 Train Prc (W): 0.6702 Train Rcl (W): 0.6622 Train F1 (W): 0.6637 \n",
            "Valid Loss: 0.6999 Valid Acc (M): 0.5598 Valid Prc (M): 0.7217 Valid Rcl (M): 0.7374 Valid F1 (M): 0.6813 Valid Acc (W): 0.6050 Valid Prc (W): 0.7751 Valid Rcl (W): 0.7260 Valid F1 (W): 0.7203\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.7196 Train Acc (M): 0.6101 Train Prc (M): 0.7126 Train Rcl (M): 0.7413 Train F1 (M): 0.7227 Train Acc (W): 0.6330 Train Prc (W): 0.7393 Train Rcl (W): 0.7390 Train F1 (W): 0.7374 \n",
            "Valid Loss: 0.5686 Valid Acc (M): 0.6945 Valid Prc (M): 0.8051 Valid Rcl (M): 0.7863 Valid F1 (M): 0.7837 Valid Acc (W): 0.6797 Valid Prc (W): 0.7950 Valid Rcl (W): 0.7764 Valid F1 (W): 0.7727\n",
            "Performance improved... (0.7372136852890744->0.7836992385937214)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6418 Train Acc (M): 0.6636 Train Prc (M): 0.7579 Train Rcl (M): 0.7751 Train F1 (M): 0.7652 Train Acc (W): 0.6669 Train Prc (W): 0.7653 Train Rcl (W): 0.7667 Train F1 (W): 0.7653 \n",
            "Valid Loss: 0.5140 Valid Acc (M): 0.7435 Valid Prc (M): 0.8367 Valid Rcl (M): 0.8353 Valid F1 (M): 0.8330 Valid Acc (W): 0.7375 Valid Prc (W): 0.8317 Valid Rcl (W): 0.8317 Valid F1 (W): 0.8288\n",
            "Performance improved... (0.7836992385937214->0.833015767228204)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5846 Train Acc (M): 0.6981 Train Prc (M): 0.7900 Train Rcl (M): 0.7987 Train F1 (M): 0.7938 Train Acc (W): 0.6919 Train Prc (W): 0.7879 Train Rcl (W): 0.7900 Train F1 (W): 0.7885 \n",
            "Valid Loss: 0.5179 Valid Acc (M): 0.7467 Valid Prc (M): 0.8369 Valid Rcl (M): 0.8374 Valid F1 (M): 0.8367 Valid Acc (W): 0.7395 Valid Prc (W): 0.8336 Valid Rcl (W): 0.8301 Valid F1 (W): 0.8314\n",
            "Performance improved... (0.833015767228204->0.8367324651421422)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5593 Train Acc (M): 0.7092 Train Prc (M): 0.8012 Train Rcl (M): 0.8084 Train F1 (M): 0.8043 Train Acc (W): 0.7039 Train Prc (W): 0.7991 Train Rcl (W): 0.8010 Train F1 (W): 0.7996 \n",
            "Valid Loss: 0.4812 Valid Acc (M): 0.7615 Valid Prc (M): 0.8482 Valid Rcl (M): 0.8473 Valid F1 (M): 0.8473 Valid Acc (W): 0.7519 Valid Prc (W): 0.8427 Valid Rcl (W): 0.8398 Valid F1 (W): 0.8408\n",
            "Performance improved... (0.8367324651421422->0.8473228838626774)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5481 Train Acc (M): 0.7154 Train Prc (M): 0.8061 Train Rcl (M): 0.8148 Train F1 (M): 0.8098 Train Acc (W): 0.7105 Train Prc (W): 0.8051 Train Rcl (W): 0.8073 Train F1 (W): 0.8056 \n",
            "Valid Loss: 0.4631 Valid Acc (M): 0.7727 Valid Prc (M): 0.8578 Valid Rcl (M): 0.8576 Valid F1 (M): 0.8569 Valid Acc (W): 0.7643 Valid Prc (W): 0.8533 Valid Rcl (W): 0.8512 Valid F1 (W): 0.8514\n",
            "Performance improved... (0.8473228838626774->0.856869098698102)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5159 Train Acc (M): 0.7323 Train Prc (M): 0.8236 Train Rcl (M): 0.8247 Train F1 (M): 0.8235 Train Acc (W): 0.7224 Train Prc (W): 0.8163 Train Rcl (W): 0.8183 Train F1 (W): 0.8165 \n",
            "Valid Loss: 0.4501 Valid Acc (M): 0.7715 Valid Prc (M): 0.8576 Valid Rcl (M): 0.8573 Valid F1 (M): 0.8564 Valid Acc (W): 0.7629 Valid Prc (W): 0.8533 Valid Rcl (W): 0.8504 Valid F1 (W): 0.8507\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.5024 Train Acc (M): 0.7373 Train Prc (M): 0.8284 Train Rcl (M): 0.8312 Train F1 (M): 0.8291 Train Acc (W): 0.7300 Train Prc (W): 0.8235 Train Rcl (W): 0.8253 Train F1 (W): 0.8237 \n",
            "Valid Loss: 0.4379 Valid Acc (M): 0.7777 Valid Prc (M): 0.8616 Valid Rcl (M): 0.8610 Valid F1 (M): 0.8607 Valid Acc (W): 0.7700 Valid Prc (W): 0.8574 Valid Rcl (W): 0.8553 Valid F1 (W): 0.8557\n",
            "Performance improved... (0.856869098698102->0.8606752306885419)\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4818 Train Acc (M): 0.7460 Train Prc (M): 0.8361 Train Rcl (M): 0.8362 Train F1 (M): 0.8354 Train Acc (W): 0.7367 Train Prc (W): 0.8290 Train Rcl (W): 0.8308 Train F1 (W): 0.8290 \n",
            "Valid Loss: 0.4191 Valid Acc (M): 0.7876 Valid Prc (M): 0.8701 Valid Rcl (M): 0.8694 Valid F1 (M): 0.8695 Valid Acc (W): 0.7802 Valid Prc (W): 0.8650 Valid Rcl (W): 0.8650 Valid F1 (W): 0.8648\n",
            "Performance improved... (0.8606752306885419->0.8695027306591747)\n",
            "\n",
            "Fold 5/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0707, 0.9284, 5.8867, 0.8614, 0.8778, 0.8446, 0.8550, 0.8582])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.6126 Train Acc (M): 0.2191 Train Prc (M): 0.3519 Train Rcl (M): 0.3647 Train F1 (M): 0.3299 Train Acc (W): 0.2448 Train Prc (W): 0.3953 Train Rcl (W): 0.3640 Train F1 (W): 0.3649 \n",
            "Valid Loss: 0.9214 Valid Acc (M): 0.5024 Valid Prc (M): 0.6505 Valid Rcl (M): 0.6439 Valid F1 (M): 0.6006 Valid Acc (W): 0.5432 Valid Prc (W): 0.6919 Valid Rcl (W): 0.6732 Valid F1 (W): 0.6340\n",
            "Performance improved... (0.0->0.6006126241620383)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.9208 Train Acc (M): 0.5025 Train Prc (M): 0.6152 Train Rcl (M): 0.6429 Train F1 (M): 0.6195 Train Acc (W): 0.5413 Train Prc (W): 0.6617 Train Rcl (W): 0.6497 Train F1 (W): 0.6523 \n",
            "Valid Loss: 0.6542 Valid Acc (M): 0.5995 Valid Prc (M): 0.7400 Valid Rcl (M): 0.7558 Valid F1 (M): 0.7132 Valid Acc (W): 0.6423 Valid Prc (W): 0.7874 Valid Rcl (W): 0.7512 Valid F1 (W): 0.7473\n",
            "Performance improved... (0.6006126241620383->0.7131800018268418)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.7136 Train Acc (M): 0.6028 Train Prc (M): 0.7076 Train Rcl (M): 0.7378 Train F1 (M): 0.7172 Train Acc (W): 0.6349 Train Prc (W): 0.7438 Train Rcl (W): 0.7409 Train F1 (W): 0.7405 \n",
            "Valid Loss: 0.5659 Valid Acc (M): 0.6741 Valid Prc (M): 0.7749 Valid Rcl (M): 0.7787 Valid F1 (M): 0.7739 Valid Acc (W): 0.6850 Valid Prc (W): 0.7833 Valid Rcl (W): 0.7805 Valid F1 (W): 0.7788\n",
            "Performance improved... (0.7131800018268418->0.7739345659309039)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6381 Train Acc (M): 0.6498 Train Prc (M): 0.7473 Train Rcl (M): 0.7713 Train F1 (M): 0.7568 Train Acc (W): 0.6657 Train Prc (W): 0.7666 Train Rcl (W): 0.7672 Train F1 (W): 0.7660 \n",
            "Valid Loss: 0.5231 Valid Acc (M): 0.6938 Valid Prc (M): 0.7935 Valid Rcl (M): 0.8111 Valid F1 (M): 0.7953 Valid Acc (W): 0.7126 Valid Prc (W): 0.8128 Valid Rcl (W): 0.8114 Valid F1 (W): 0.8069\n",
            "Performance improved... (0.7739345659309039->0.7952671147769373)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5900 Train Acc (M): 0.6758 Train Prc (M): 0.7718 Train Rcl (M): 0.7917 Train F1 (M): 0.7799 Train Acc (W): 0.6862 Train Prc (W): 0.7854 Train Rcl (W): 0.7868 Train F1 (W): 0.7853 \n",
            "Valid Loss: 0.4996 Valid Acc (M): 0.7220 Valid Prc (M): 0.8159 Valid Rcl (M): 0.8191 Valid F1 (M): 0.8138 Valid Acc (W): 0.7218 Valid Prc (W): 0.8162 Valid Rcl (W): 0.8163 Valid F1 (W): 0.8122\n",
            "Performance improved... (0.7952671147769373->0.8137840574261128)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5569 Train Acc (M): 0.7013 Train Prc (M): 0.7932 Train Rcl (M): 0.8052 Train F1 (M): 0.7980 Train Acc (W): 0.7006 Train Prc (W): 0.7959 Train Rcl (W): 0.7984 Train F1 (W): 0.7962 \n",
            "Valid Loss: 0.4796 Valid Acc (M): 0.7118 Valid Prc (M): 0.8037 Valid Rcl (M): 0.8192 Valid F1 (M): 0.8096 Valid Acc (W): 0.7223 Valid Prc (W): 0.8150 Valid Rcl (W): 0.8179 Valid F1 (W): 0.8151\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5464 Train Acc (M): 0.7096 Train Prc (M): 0.8013 Train Rcl (M): 0.8123 Train F1 (M): 0.8055 Train Acc (W): 0.7092 Train Prc (W): 0.8038 Train Rcl (W): 0.8065 Train F1 (W): 0.8040 \n",
            "Valid Loss: 0.4624 Valid Acc (M): 0.7304 Valid Prc (M): 0.8251 Valid Rcl (M): 0.8306 Valid F1 (M): 0.8240 Valid Acc (W): 0.7336 Valid Prc (W): 0.8284 Valid Rcl (W): 0.8293 Valid F1 (W): 0.8247\n",
            "Performance improved... (0.8137840574261128->0.823972494285472)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5219 Train Acc (M): 0.7169 Train Prc (M): 0.8077 Train Rcl (M): 0.8175 Train F1 (M): 0.8117 Train Acc (W): 0.7149 Train Prc (W): 0.8089 Train Rcl (W): 0.8113 Train F1 (W): 0.8093 \n",
            "Valid Loss: 0.4535 Valid Acc (M): 0.7374 Valid Prc (M): 0.8317 Valid Rcl (M): 0.8355 Valid F1 (M): 0.8307 Valid Acc (W): 0.7419 Valid Prc (W): 0.8343 Valid Rcl (W): 0.8366 Valid F1 (W): 0.8327\n",
            "Performance improved... (0.823972494285472->0.8307132067837374)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4996 Train Acc (M): 0.7315 Train Prc (M): 0.8216 Train Rcl (M): 0.8264 Train F1 (M): 0.8229 Train Acc (W): 0.7253 Train Prc (W): 0.8182 Train Rcl (W): 0.8204 Train F1 (W): 0.8181 \n",
            "Valid Loss: 0.4499 Valid Acc (M): 0.7394 Valid Prc (M): 0.8341 Valid Rcl (M): 0.8369 Valid F1 (M): 0.8308 Valid Acc (W): 0.7403 Valid Prc (W): 0.8361 Valid Rcl (W): 0.8341 Valid F1 (W): 0.8302\n",
            "Performance improved... (0.8307132067837374->0.830805554882265)\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4933 Train Acc (M): 0.7372 Train Prc (M): 0.8280 Train Rcl (M): 0.8315 Train F1 (M): 0.8289 Train Acc (W): 0.7306 Train Prc (W): 0.8240 Train Rcl (W): 0.8259 Train F1 (W): 0.8241 \n",
            "Valid Loss: 0.4563 Valid Acc (M): 0.7337 Valid Prc (M): 0.8438 Valid Rcl (M): 0.8307 Valid F1 (M): 0.8260 Valid Acc (W): 0.7354 Valid Prc (W): 0.8409 Valid Rcl (W): 0.8341 Valid F1 (W): 0.8265\n",
            "\n",
            "Fold 6/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0707, 0.9284, 5.8867, 0.8614, 0.8783, 0.8440, 0.8550, 0.8582])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.6193 Train Acc (M): 0.2342 Train Prc (M): 0.3635 Train Rcl (M): 0.3883 Train F1 (M): 0.3466 Train Acc (W): 0.2614 Train Prc (W): 0.4071 Train Rcl (W): 0.3814 Train F1 (W): 0.3823 \n",
            "Valid Loss: 0.8920 Valid Acc (M): 0.5761 Valid Prc (M): 0.6855 Valid Rcl (M): 0.7128 Valid F1 (M): 0.6866 Valid Acc (W): 0.6129 Valid Prc (W): 0.7216 Valid Rcl (W): 0.7301 Valid F1 (W): 0.7158\n",
            "Performance improved... (0.0->0.6865786161919534)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8579 Train Acc (M): 0.5359 Train Prc (M): 0.6465 Train Rcl (M): 0.6770 Train F1 (M): 0.6540 Train Acc (W): 0.5708 Train Prc (W): 0.6874 Train Rcl (W): 0.6810 Train F1 (W): 0.6816 \n",
            "Valid Loss: 0.6430 Valid Acc (M): 0.6407 Valid Prc (M): 0.7555 Valid Rcl (M): 0.7741 Valid F1 (M): 0.7477 Valid Acc (W): 0.6562 Valid Prc (W): 0.7778 Valid Rcl (W): 0.7618 Valid F1 (W): 0.7571\n",
            "Performance improved... (0.6865786161919534->0.7477445208813962)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.6668 Train Acc (M): 0.6367 Train Prc (M): 0.7351 Train Rcl (M): 0.7595 Train F1 (M): 0.7447 Train Acc (W): 0.6515 Train Prc (W): 0.7531 Train Rcl (W): 0.7549 Train F1 (W): 0.7529 \n",
            "Valid Loss: 0.5695 Valid Acc (M): 0.7144 Valid Prc (M): 0.8057 Valid Rcl (M): 0.8089 Valid F1 (M): 0.8046 Valid Acc (W): 0.6957 Valid Prc (W): 0.7969 Valid Rcl (W): 0.7927 Valid F1 (W): 0.7918\n",
            "Performance improved... (0.7477445208813962->0.804570307936229)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.5991 Train Acc (M): 0.6858 Train Prc (M): 0.7788 Train Rcl (M): 0.7865 Train F1 (M): 0.7821 Train Acc (W): 0.6814 Train Prc (W): 0.7769 Train Rcl (W): 0.7795 Train F1 (W): 0.7777 \n",
            "Valid Loss: 0.5372 Valid Acc (M): 0.7238 Valid Prc (M): 0.8120 Valid Rcl (M): 0.8210 Valid F1 (M): 0.8147 Valid Acc (W): 0.7113 Valid Prc (W): 0.8064 Valid Rcl (W): 0.8098 Valid F1 (W): 0.8062\n",
            "Performance improved... (0.804570307936229->0.8147160858001263)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5728 Train Acc (M): 0.7059 Train Prc (M): 0.7978 Train Rcl (M): 0.8032 Train F1 (M): 0.7998 Train Acc (W): 0.6992 Train Prc (W): 0.7938 Train Rcl (W): 0.7968 Train F1 (W): 0.7946 \n",
            "Valid Loss: 0.5159 Valid Acc (M): 0.7364 Valid Prc (M): 0.8233 Valid Rcl (M): 0.8310 Valid F1 (M): 0.8266 Valid Acc (W): 0.7244 Valid Prc (W): 0.8181 Valid Rcl (W): 0.8195 Valid F1 (W): 0.8184\n",
            "Performance improved... (0.8147160858001263->0.8265873935298818)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5406 Train Acc (M): 0.7141 Train Prc (M): 0.8062 Train Rcl (M): 0.8123 Train F1 (M): 0.8085 Train Acc (W): 0.7100 Train Prc (W): 0.8042 Train Rcl (W): 0.8066 Train F1 (W): 0.8047 \n",
            "Valid Loss: 0.5036 Valid Acc (M): 0.7450 Valid Prc (M): 0.8322 Valid Rcl (M): 0.8373 Valid F1 (M): 0.8341 Valid Acc (W): 0.7284 Valid Prc (W): 0.8228 Valid Rcl (W): 0.8252 Valid F1 (W): 0.8232\n",
            "Performance improved... (0.8265873935298818->0.8340823111148572)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5203 Train Acc (M): 0.7296 Train Prc (M): 0.8208 Train Rcl (M): 0.8227 Train F1 (M): 0.8211 Train Acc (W): 0.7221 Train Prc (W): 0.8153 Train Rcl (W): 0.8173 Train F1 (W): 0.8156 \n",
            "Valid Loss: 0.4860 Valid Acc (M): 0.7487 Valid Prc (M): 0.8354 Valid Rcl (M): 0.8409 Valid F1 (M): 0.8370 Valid Acc (W): 0.7328 Valid Prc (W): 0.8274 Valid Rcl (W): 0.8285 Valid F1 (W): 0.8267\n",
            "Performance improved... (0.8340823111148572->0.8369901369408775)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.4970 Train Acc (M): 0.7407 Train Prc (M): 0.8319 Train Rcl (M): 0.8321 Train F1 (M): 0.8310 Train Acc (W): 0.7331 Train Prc (W): 0.8258 Train Rcl (W): 0.8277 Train F1 (W): 0.8257 \n",
            "Valid Loss: 0.4593 Valid Acc (M): 0.7639 Valid Prc (M): 0.8526 Valid Rcl (M): 0.8480 Valid F1 (M): 0.8485 Valid Acc (W): 0.7456 Valid Prc (W): 0.8396 Valid Rcl (W): 0.8390 Valid F1 (W): 0.8375\n",
            "Performance improved... (0.8369901369408775->0.8484964911749756)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4888 Train Acc (M): 0.7430 Train Prc (M): 0.8335 Train Rcl (M): 0.8348 Train F1 (M): 0.8331 Train Acc (W): 0.7359 Train Prc (W): 0.8283 Train Rcl (W): 0.8300 Train F1 (W): 0.8280 \n",
            "Valid Loss: 0.4559 Valid Acc (M): 0.7661 Valid Prc (M): 0.8529 Valid Rcl (M): 0.8551 Valid F1 (M): 0.8521 Valid Acc (W): 0.7512 Valid Prc (W): 0.8448 Valid Rcl (W): 0.8447 Valid F1 (W): 0.8426\n",
            "Performance improved... (0.8484964911749756->0.852077086145761)\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4678 Train Acc (M): 0.7593 Train Prc (M): 0.8485 Train Rcl (M): 0.8466 Train F1 (M): 0.8465 Train Acc (W): 0.7508 Train Prc (W): 0.8415 Train Rcl (W): 0.8425 Train F1 (W): 0.8409 \n",
            "Valid Loss: 0.4397 Valid Acc (M): 0.7838 Valid Prc (M): 0.8694 Valid Rcl (M): 0.8649 Valid F1 (M): 0.8651 Valid Acc (W): 0.7666 Valid Prc (W): 0.8572 Valid Rcl (W): 0.8569 Valid F1 (W): 0.8549\n",
            "Performance improved... (0.852077086145761->0.8651272648959043)\n",
            "\n",
            "Fold 7/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0716, 0.9278, 5.8867, 0.8614, 0.8778, 0.8440, 0.8555, 0.8582])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.7220 Train Acc (M): 0.1938 Train Prc (M): 0.3213 Train Rcl (M): 0.3374 Train F1 (M): 0.3024 Train Acc (W): 0.2136 Train Prc (W): 0.3580 Train Rcl (W): 0.3360 Train F1 (W): 0.3303 \n",
            "Valid Loss: 0.8701 Valid Acc (M): 0.6365 Valid Prc (M): 0.7619 Valid Rcl (M): 0.7361 Valid F1 (M): 0.7424 Valid Acc (W): 0.6766 Valid Prc (W): 0.7724 Valid Rcl (W): 0.7772 Valid F1 (W): 0.7725\n",
            "Performance improved... (0.0->0.7423865977328267)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8909 Train Acc (M): 0.5142 Train Prc (M): 0.6294 Train Rcl (M): 0.6602 Train F1 (M): 0.6319 Train Acc (W): 0.5578 Train Prc (W): 0.6819 Train Rcl (W): 0.6683 Train F1 (W): 0.6703 \n",
            "Valid Loss: 0.6362 Valid Acc (M): 0.5985 Valid Prc (M): 0.7280 Valid Rcl (M): 0.7561 Valid F1 (M): 0.7188 Valid Acc (W): 0.6445 Valid Prc (W): 0.7829 Valid Rcl (W): 0.7553 Valid F1 (W): 0.7575\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.7081 Train Acc (M): 0.6029 Train Prc (M): 0.7090 Train Rcl (M): 0.7449 Train F1 (M): 0.7185 Train Acc (W): 0.6367 Train Prc (W): 0.7492 Train Rcl (W): 0.7427 Train F1 (W): 0.7435 \n",
            "Valid Loss: 0.5483 Valid Acc (M): 0.7102 Valid Prc (M): 0.8171 Valid Rcl (M): 0.7978 Valid F1 (M): 0.8030 Valid Acc (W): 0.7100 Valid Prc (W): 0.8084 Valid Rcl (W): 0.8024 Valid F1 (W): 0.8011\n",
            "Performance improved... (0.7423865977328267->0.8029845450553357)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6269 Train Acc (M): 0.6573 Train Prc (M): 0.7548 Train Rcl (M): 0.7731 Train F1 (M): 0.7624 Train Acc (W): 0.6664 Train Prc (W): 0.7665 Train Rcl (W): 0.7680 Train F1 (W): 0.7665 \n",
            "Valid Loss: 0.5073 Valid Acc (M): 0.7334 Valid Prc (M): 0.8274 Valid Rcl (M): 0.8277 Valid F1 (M): 0.8237 Valid Acc (W): 0.7353 Valid Prc (W): 0.8268 Valid Rcl (W): 0.8293 Valid F1 (W): 0.8240\n",
            "Performance improved... (0.8029845450553357->0.8236852582599796)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5757 Train Acc (M): 0.6992 Train Prc (M): 0.7924 Train Rcl (M): 0.8029 Train F1 (M): 0.7967 Train Acc (W): 0.6962 Train Prc (W): 0.7930 Train Rcl (W): 0.7952 Train F1 (W): 0.7934 \n",
            "Valid Loss: 0.4779 Valid Acc (M): 0.7482 Valid Prc (M): 0.8412 Valid Rcl (M): 0.8381 Valid F1 (M): 0.8360 Valid Acc (W): 0.7471 Valid Prc (W): 0.8377 Valid Rcl (W): 0.8390 Valid F1 (W): 0.8344\n",
            "Performance improved... (0.8236852582599796->0.8360254406164422)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5452 Train Acc (M): 0.7199 Train Prc (M): 0.8109 Train Rcl (M): 0.8149 Train F1 (M): 0.8122 Train Acc (W): 0.7107 Train Prc (W): 0.8050 Train Rcl (W): 0.8074 Train F1 (W): 0.8054 \n",
            "Valid Loss: 0.4587 Valid Acc (M): 0.7596 Valid Prc (M): 0.8484 Valid Rcl (M): 0.8445 Valid F1 (M): 0.8454 Valid Acc (W): 0.7555 Valid Prc (W): 0.8420 Valid Rcl (W): 0.8447 Valid F1 (W): 0.8423\n",
            "Performance improved... (0.8360254406164422->0.845396432315038)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5211 Train Acc (M): 0.7317 Train Prc (M): 0.8232 Train Rcl (M): 0.8233 Train F1 (M): 0.8226 Train Acc (W): 0.7216 Train Prc (W): 0.8154 Train Rcl (W): 0.8169 Train F1 (W): 0.8155 \n",
            "Valid Loss: 0.4420 Valid Acc (M): 0.7700 Valid Prc (M): 0.8576 Valid Rcl (M): 0.8538 Valid F1 (M): 0.8544 Valid Acc (W): 0.7668 Valid Prc (W): 0.8522 Valid Rcl (W): 0.8545 Valid F1 (W): 0.8520\n",
            "Performance improved... (0.845396432315038->0.8544014281122976)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5037 Train Acc (M): 0.7412 Train Prc (M): 0.8310 Train Rcl (M): 0.8314 Train F1 (M): 0.8307 Train Acc (W): 0.7297 Train Prc (W): 0.8228 Train Rcl (W): 0.8245 Train F1 (W): 0.8230 \n",
            "Valid Loss: 0.4285 Valid Acc (M): 0.7753 Valid Prc (M): 0.8611 Valid Rcl (M): 0.8601 Valid F1 (M): 0.8597 Valid Acc (W): 0.7755 Valid Prc (W): 0.8590 Valid Rcl (W): 0.8610 Valid F1 (W): 0.8590\n",
            "Performance improved... (0.8544014281122976->0.8596915203609534)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4859 Train Acc (M): 0.7499 Train Prc (M): 0.8395 Train Rcl (M): 0.8383 Train F1 (M): 0.8383 Train Acc (W): 0.7375 Train Prc (W): 0.8301 Train Rcl (W): 0.8318 Train F1 (W): 0.8303 \n",
            "Valid Loss: 0.4337 Valid Acc (M): 0.7539 Valid Prc (M): 0.8489 Valid Rcl (M): 0.8489 Valid F1 (M): 0.8429 Valid Acc (W): 0.7556 Valid Prc (W): 0.8514 Valid Rcl (W): 0.8472 Valid F1 (W): 0.8429\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4730 Train Acc (M): 0.7516 Train Prc (M): 0.8411 Train Rcl (M): 0.8412 Train F1 (M): 0.8404 Train Acc (W): 0.7422 Train Prc (W): 0.8342 Train Rcl (W): 0.8356 Train F1 (W): 0.8341 \n",
            "Valid Loss: 0.4112 Valid Acc (M): 0.7790 Valid Prc (M): 0.8697 Valid Rcl (M): 0.8602 Valid F1 (M): 0.8626 Valid Acc (W): 0.7755 Valid Prc (W): 0.8626 Valid Rcl (W): 0.8618 Valid F1 (W): 0.8600\n",
            "Performance improved... (0.8596915203609534->0.8626403619050222)\n",
            "\n",
            "Fold 8/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0716, 0.9279, 5.8872, 0.8609, 0.8779, 0.8441, 0.8556, 0.8583])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.5313 Train Acc (M): 0.2758 Train Prc (M): 0.4159 Train Rcl (M): 0.4235 Train F1 (M): 0.4042 Train Acc (W): 0.3035 Train Prc (W): 0.4598 Train Rcl (W): 0.4353 Train F1 (W): 0.4388 \n",
            "Valid Loss: 0.8077 Valid Acc (M): 0.5541 Valid Prc (M): 0.6724 Valid Rcl (M): 0.6994 Valid F1 (M): 0.6730 Valid Acc (W): 0.6020 Valid Prc (W): 0.7254 Valid Rcl (W): 0.7168 Valid F1 (W): 0.7153\n",
            "Performance improved... (0.0->0.6730066868260816)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8287 Train Acc (M): 0.5436 Train Prc (M): 0.6544 Train Rcl (M): 0.6874 Train F1 (M): 0.6614 Train Acc (W): 0.5842 Train Prc (W): 0.7011 Train Rcl (W): 0.6957 Train F1 (W): 0.6949 \n",
            "Valid Loss: 0.6216 Valid Acc (M): 0.6460 Valid Prc (M): 0.7616 Valid Rcl (M): 0.8011 Valid F1 (M): 0.7620 Valid Acc (W): 0.6785 Valid Prc (W): 0.8035 Valid Rcl (W): 0.7876 Valid F1 (W): 0.7856\n",
            "Performance improved... (0.6730066868260816->0.761982546952418)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.6980 Train Acc (M): 0.6186 Train Prc (M): 0.7215 Train Rcl (M): 0.7504 Train F1 (M): 0.7316 Train Acc (W): 0.6450 Train Prc (W): 0.7511 Train Rcl (W): 0.7514 Train F1 (W): 0.7495 \n",
            "Valid Loss: 0.5463 Valid Acc (M): 0.7209 Valid Prc (M): 0.8127 Valid Rcl (M): 0.8276 Valid F1 (M): 0.8165 Valid Acc (W): 0.7179 Valid Prc (W): 0.8164 Valid Rcl (W): 0.8169 Valid F1 (W): 0.8134\n",
            "Performance improved... (0.761982546952418->0.8164795564797218)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6262 Train Acc (M): 0.6668 Train Prc (M): 0.7645 Train Rcl (M): 0.7865 Train F1 (M): 0.7732 Train Acc (W): 0.6802 Train Prc (W): 0.7809 Train Rcl (W): 0.7823 Train F1 (W): 0.7806 \n",
            "Valid Loss: 0.5196 Valid Acc (M): 0.7014 Valid Prc (M): 0.8017 Valid Rcl (M): 0.8296 Valid F1 (M): 0.8068 Valid Acc (W): 0.7163 Valid Prc (W): 0.8240 Valid Rcl (W): 0.8194 Valid F1 (W): 0.8158\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5961 Train Acc (M): 0.6815 Train Prc (M): 0.7771 Train Rcl (M): 0.7961 Train F1 (M): 0.7848 Train Acc (W): 0.6905 Train Prc (W): 0.7893 Train Rcl (W): 0.7912 Train F1 (W): 0.7893 \n",
            "Valid Loss: 0.4878 Valid Acc (M): 0.7495 Valid Prc (M): 0.8485 Valid Rcl (M): 0.8364 Valid F1 (M): 0.8344 Valid Acc (W): 0.7316 Valid Prc (W): 0.8346 Valid Rcl (W): 0.8299 Valid F1 (W): 0.8239\n",
            "Performance improved... (0.8164795564797218->0.8344182594077001)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5542 Train Acc (M): 0.7105 Train Prc (M): 0.8032 Train Rcl (M): 0.8120 Train F1 (M): 0.8067 Train Acc (W): 0.7084 Train Prc (W): 0.8039 Train Rcl (W): 0.8063 Train F1 (W): 0.8043 \n",
            "Valid Loss: 0.4634 Valid Acc (M): 0.7608 Valid Prc (M): 0.8544 Valid Rcl (M): 0.8493 Valid F1 (M): 0.8467 Valid Acc (W): 0.7478 Valid Prc (W): 0.8454 Valid Rcl (W): 0.8430 Valid F1 (W): 0.8389\n",
            "Performance improved... (0.8344182594077001->0.8466844327435774)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5319 Train Acc (M): 0.7253 Train Prc (M): 0.8175 Train Rcl (M): 0.8217 Train F1 (M): 0.8187 Train Acc (W): 0.7204 Train Prc (W): 0.8144 Train Rcl (W): 0.8171 Train F1 (W): 0.8148 \n",
            "Valid Loss: 0.4467 Valid Acc (M): 0.7642 Valid Prc (M): 0.8542 Valid Rcl (M): 0.8525 Valid F1 (M): 0.8502 Valid Acc (W): 0.7503 Valid Prc (W): 0.8455 Valid Rcl (W): 0.8446 Valid F1 (W): 0.8416\n",
            "Performance improved... (0.8466844327435774->0.8501516197223702)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5131 Train Acc (M): 0.7330 Train Prc (M): 0.8240 Train Rcl (M): 0.8284 Train F1 (M): 0.8252 Train Acc (W): 0.7277 Train Prc (W): 0.8213 Train Rcl (W): 0.8232 Train F1 (W): 0.8212 \n",
            "Valid Loss: 0.4334 Valid Acc (M): 0.7798 Valid Prc (M): 0.8638 Valid Rcl (M): 0.8614 Valid F1 (M): 0.8609 Valid Acc (W): 0.7628 Valid Prc (W): 0.8526 Valid Rcl (W): 0.8527 Valid F1 (W): 0.8508\n",
            "Performance improved... (0.8501516197223702->0.8608630782744403)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4902 Train Acc (M): 0.7440 Train Prc (M): 0.8341 Train Rcl (M): 0.8383 Train F1 (M): 0.8352 Train Acc (W): 0.7395 Train Prc (W): 0.8319 Train Rcl (W): 0.8336 Train F1 (W): 0.8318 \n",
            "Valid Loss: 0.4134 Valid Acc (M): 0.7758 Valid Prc (M): 0.8653 Valid Rcl (M): 0.8578 Valid F1 (M): 0.8584 Valid Acc (W): 0.7583 Valid Prc (W): 0.8521 Valid Rcl (W): 0.8503 Valid F1 (W): 0.8480\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4744 Train Acc (M): 0.7569 Train Prc (M): 0.8461 Train Rcl (M): 0.8467 Train F1 (M): 0.8455 Train Acc (W): 0.7499 Train Prc (W): 0.8412 Train Rcl (W): 0.8422 Train F1 (W): 0.8408 \n",
            "Valid Loss: 0.3974 Valid Acc (M): 0.7993 Valid Prc (M): 0.8857 Valid Rcl (M): 0.8767 Valid F1 (M): 0.8770 Valid Acc (W): 0.7833 Valid Prc (W): 0.8746 Valid Rcl (W): 0.8698 Valid F1 (W): 0.8677\n",
            "Performance improved... (0.8608630782744403->0.877043399752848)\n",
            "\n",
            "Fold 9/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0716, 0.9279, 5.8872, 0.8609, 0.8779, 0.8441, 0.8556, 0.8583])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.5755 Train Acc (M): 0.2704 Train Prc (M): 0.3942 Train Rcl (M): 0.4184 Train F1 (M): 0.3971 Train Acc (W): 0.2983 Train Prc (W): 0.4329 Train Rcl (W): 0.4482 Train F1 (W): 0.4325 \n",
            "Valid Loss: 0.8769 Valid Acc (M): 0.5397 Valid Prc (M): 0.6967 Valid Rcl (M): 0.6810 Valid F1 (M): 0.6559 Valid Acc (W): 0.5989 Valid Prc (W): 0.7642 Valid Rcl (W): 0.7177 Valid F1 (W): 0.7140\n",
            "Performance improved... (0.0->0.6558849015921486)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8531 Train Acc (M): 0.5372 Train Prc (M): 0.6470 Train Rcl (M): 0.6788 Train F1 (M): 0.6528 Train Acc (W): 0.5799 Train Prc (W): 0.6967 Train Rcl (W): 0.6875 Train F1 (W): 0.6886 \n",
            "Valid Loss: 0.6619 Valid Acc (M): 0.6482 Valid Prc (M): 0.7562 Valid Rcl (M): 0.7624 Valid F1 (M): 0.7587 Valid Acc (W): 0.6736 Valid Prc (W): 0.7755 Valid Rcl (W): 0.7771 Valid F1 (W): 0.7757\n",
            "Performance improved... (0.6558849015921486->0.7586931213185955)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.6706 Train Acc (M): 0.6323 Train Prc (M): 0.7334 Train Rcl (M): 0.7582 Train F1 (M): 0.7428 Train Acc (W): 0.6549 Train Prc (W): 0.7586 Train Rcl (W): 0.7579 Train F1 (W): 0.7573 \n",
            "Valid Loss: 0.5896 Valid Acc (M): 0.6940 Valid Prc (M): 0.7928 Valid Rcl (M): 0.7978 Valid F1 (M): 0.7939 Valid Acc (W): 0.6932 Valid Prc (W): 0.7932 Valid Rcl (W): 0.7933 Valid F1 (W): 0.7919\n",
            "Performance improved... (0.7586931213185955->0.7938966439277454)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6100 Train Acc (M): 0.6760 Train Prc (M): 0.7724 Train Rcl (M): 0.7886 Train F1 (M): 0.7793 Train Acc (W): 0.6843 Train Prc (W): 0.7832 Train Rcl (W): 0.7842 Train F1 (W): 0.7832 \n",
            "Valid Loss: 0.5593 Valid Acc (M): 0.7002 Valid Prc (M): 0.7988 Valid Rcl (M): 0.8075 Valid F1 (M): 0.8008 Valid Acc (W): 0.7036 Valid Prc (W): 0.8027 Valid Rcl (W): 0.8055 Valid F1 (W): 0.8020\n",
            "Performance improved... (0.7938966439277454->0.800805466852187)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5748 Train Acc (M): 0.7001 Train Prc (M): 0.7928 Train Rcl (M): 0.8030 Train F1 (M): 0.7973 Train Acc (W): 0.6982 Train Prc (W): 0.7943 Train Rcl (W): 0.7959 Train F1 (W): 0.7947 \n",
            "Valid Loss: 0.5408 Valid Acc (M): 0.7145 Valid Prc (M): 0.8153 Valid Rcl (M): 0.8079 Valid F1 (M): 0.8110 Valid Acc (W): 0.7096 Valid Prc (W): 0.8069 Valid Rcl (W): 0.8080 Valid F1 (W): 0.8069\n",
            "Performance improved... (0.800805466852187->0.8109562927066061)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5468 Train Acc (M): 0.7154 Train Prc (M): 0.8076 Train Rcl (M): 0.8102 Train F1 (M): 0.8086 Train Acc (W): 0.7089 Train Prc (W): 0.8026 Train Rcl (W): 0.8048 Train F1 (W): 0.8034 \n",
            "Valid Loss: 0.5284 Valid Acc (M): 0.7152 Valid Prc (M): 0.8108 Valid Rcl (M): 0.8182 Valid F1 (M): 0.8133 Valid Acc (W): 0.7160 Valid Prc (W): 0.8130 Valid Rcl (W): 0.8145 Valid F1 (W): 0.8126\n",
            "Performance improved... (0.8109562927066061->0.8132726624604751)\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5220 Train Acc (M): 0.7224 Train Prc (M): 0.8141 Train Rcl (M): 0.8175 Train F1 (M): 0.8154 Train Acc (W): 0.7159 Train Prc (W): 0.8097 Train Rcl (W): 0.8115 Train F1 (W): 0.8102 \n",
            "Valid Loss: 0.5105 Valid Acc (M): 0.7318 Valid Prc (M): 0.8297 Valid Rcl (M): 0.8283 Valid F1 (M): 0.8257 Valid Acc (W): 0.7277 Valid Prc (W): 0.8258 Valid Rcl (W): 0.8259 Valid F1 (W): 0.8222\n",
            "Performance improved... (0.8132726624604751->0.8257037772901685)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5083 Train Acc (M): 0.7369 Train Prc (M): 0.8272 Train Rcl (M): 0.8298 Train F1 (M): 0.8279 Train Acc (W): 0.7280 Train Prc (W): 0.8213 Train Rcl (W): 0.8233 Train F1 (W): 0.8217 \n",
            "Valid Loss: 0.4882 Valid Acc (M): 0.7360 Valid Prc (M): 0.8329 Valid Rcl (M): 0.8270 Valid F1 (M): 0.8284 Valid Acc (W): 0.7289 Valid Prc (W): 0.8241 Valid Rcl (W): 0.8259 Valid F1 (W): 0.8234\n",
            "Performance improved... (0.8257037772901685->0.8284074549860885)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4909 Train Acc (M): 0.7447 Train Prc (M): 0.8338 Train Rcl (M): 0.8352 Train F1 (M): 0.8339 Train Acc (W): 0.7359 Train Prc (W): 0.8276 Train Rcl (W): 0.8293 Train F1 (W): 0.8278 \n",
            "Valid Loss: 0.4792 Valid Acc (M): 0.7358 Valid Prc (M): 0.8406 Valid Rcl (M): 0.8271 Valid F1 (M): 0.8282 Valid Acc (W): 0.7292 Valid Prc (W): 0.8308 Valid Rcl (W): 0.8275 Valid F1 (W): 0.8236\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4767 Train Acc (M): 0.7462 Train Prc (M): 0.8347 Train Rcl (M): 0.8389 Train F1 (M): 0.8363 Train Acc (W): 0.7394 Train Prc (W): 0.8312 Train Rcl (W): 0.8328 Train F1 (W): 0.8314 \n",
            "Valid Loss: 0.4601 Valid Acc (M): 0.7483 Valid Prc (M): 0.8448 Valid Rcl (M): 0.8387 Valid F1 (M): 0.8389 Valid Acc (W): 0.7416 Valid Prc (W): 0.8371 Valid Rcl (W): 0.8373 Valid F1 (W): 0.8340\n",
            "Performance improved... (0.8284074549860885->0.8388696838945437)\n",
            "\n",
            "Fold 10/10\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0716, 0.9279, 5.8872, 0.8609, 0.8779, 0.8441, 0.8556, 0.8583])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.6341 Train Acc (M): 0.2485 Train Prc (M): 0.3748 Train Rcl (M): 0.3929 Train F1 (M): 0.3731 Train Acc (W): 0.2731 Train Prc (W): 0.4118 Train Rcl (W): 0.4160 Train F1 (W): 0.4050 \n",
            "Valid Loss: 0.9147 Valid Acc (M): 0.5661 Valid Prc (M): 0.6911 Valid Rcl (M): 0.6802 Valid F1 (M): 0.6737 Valid Acc (W): 0.6163 Valid Prc (W): 0.7217 Valid Rcl (W): 0.7339 Valid F1 (W): 0.7174\n",
            "Performance improved... (0.0->0.6737385094053654)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 0.8718 Train Acc (M): 0.5233 Train Prc (M): 0.6374 Train Rcl (M): 0.6709 Train F1 (M): 0.6416 Train Acc (W): 0.5653 Train Prc (W): 0.6880 Train Rcl (W): 0.6756 Train F1 (W): 0.6776 \n",
            "Valid Loss: 0.6808 Valid Acc (M): 0.6176 Valid Prc (M): 0.7331 Valid Rcl (M): 0.7710 Valid F1 (M): 0.7332 Valid Acc (W): 0.6591 Valid Prc (W): 0.7820 Valid Rcl (W): 0.7697 Valid F1 (W): 0.7659\n",
            "Performance improved... (0.6737385094053654->0.733224776373972)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.6980 Train Acc (M): 0.6103 Train Prc (M): 0.7135 Train Rcl (M): 0.7463 Train F1 (M): 0.7236 Train Acc (W): 0.6402 Train Prc (W): 0.7485 Train Rcl (W): 0.7449 Train F1 (W): 0.7447 \n",
            "Valid Loss: 0.6017 Valid Acc (M): 0.6639 Valid Prc (M): 0.7653 Valid Rcl (M): 0.8001 Valid F1 (M): 0.7736 Valid Acc (W): 0.6894 Valid Prc (W): 0.7973 Valid Rcl (W): 0.7925 Valid F1 (W): 0.7908\n",
            "Performance improved... (0.733224776373972->0.7736039994560571)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6281 Train Acc (M): 0.6710 Train Prc (M): 0.7681 Train Rcl (M): 0.7891 Train F1 (M): 0.7766 Train Acc (W): 0.6848 Train Prc (W): 0.7846 Train Rcl (W): 0.7859 Train F1 (W): 0.7844 \n",
            "Valid Loss: 0.5628 Valid Acc (M): 0.6929 Valid Prc (M): 0.7921 Valid Rcl (M): 0.8143 Valid F1 (M): 0.7949 Valid Acc (W): 0.7080 Valid Prc (W): 0.8123 Valid Rcl (W): 0.8088 Valid F1 (W): 0.8038\n",
            "Performance improved... (0.7736039994560571->0.7948656624739204)\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5800 Train Acc (M): 0.6956 Train Prc (M): 0.7894 Train Rcl (M): 0.8036 Train F1 (M): 0.7952 Train Acc (W): 0.6996 Train Prc (W): 0.7961 Train Rcl (W): 0.7985 Train F1 (W): 0.7965 \n",
            "Valid Loss: 0.5209 Valid Acc (M): 0.7287 Valid Prc (M): 0.8250 Valid Rcl (M): 0.8298 Valid F1 (M): 0.8220 Valid Acc (W): 0.7284 Valid Prc (W): 0.8272 Valid Rcl (W): 0.8259 Valid F1 (W): 0.8209\n",
            "Performance improved... (0.7948656624739204->0.8220039949483842)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5533 Train Acc (M): 0.7108 Train Prc (M): 0.8026 Train Rcl (M): 0.8135 Train F1 (M): 0.8069 Train Acc (W): 0.7105 Train Prc (W): 0.8052 Train Rcl (W): 0.8081 Train F1 (W): 0.8056 \n",
            "Valid Loss: 0.5052 Valid Acc (M): 0.7250 Valid Prc (M): 0.8160 Valid Rcl (M): 0.8251 Valid F1 (M): 0.8187 Valid Acc (W): 0.7244 Valid Prc (W): 0.8188 Valid Rcl (W): 0.8194 Valid F1 (W): 0.8173\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5265 Train Acc (M): 0.7245 Train Prc (M): 0.8156 Train Rcl (M): 0.8198 Train F1 (M): 0.8171 Train Acc (W): 0.7176 Train Prc (W): 0.8114 Train Rcl (W): 0.8140 Train F1 (W): 0.8121 \n",
            "Valid Loss: 0.4897 Valid Acc (M): 0.7375 Valid Prc (M): 0.8321 Valid Rcl (M): 0.8378 Valid F1 (M): 0.8301 Valid Acc (W): 0.7376 Valid Prc (W): 0.8346 Valid Rcl (W): 0.8340 Valid F1 (W): 0.8292\n",
            "Performance improved... (0.8220039949483842->0.8300538573893198)\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.5115 Train Acc (M): 0.7313 Train Prc (M): 0.8217 Train Rcl (M): 0.8257 Train F1 (M): 0.8227 Train Acc (W): 0.7252 Train Prc (W): 0.8179 Train Rcl (W): 0.8204 Train F1 (W): 0.8181 \n",
            "Valid Loss: 0.4773 Valid Acc (M): 0.7418 Valid Prc (M): 0.8376 Valid Rcl (M): 0.8390 Valid F1 (M): 0.8333 Valid Acc (W): 0.7388 Valid Prc (W): 0.8365 Valid Rcl (W): 0.8356 Valid F1 (W): 0.8308\n",
            "Performance improved... (0.8300538573893198->0.8333309031555245)\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4960 Train Acc (M): 0.7362 Train Prc (M): 0.8281 Train Rcl (M): 0.8319 Train F1 (M): 0.8287 Train Acc (W): 0.7317 Train Prc (W): 0.8254 Train Rcl (W): 0.8277 Train F1 (W): 0.8253 \n",
            "Valid Loss: 0.4713 Valid Acc (M): 0.7430 Valid Prc (M): 0.8335 Valid Rcl (M): 0.8386 Valid F1 (M): 0.8344 Valid Acc (W): 0.7402 Valid Prc (W): 0.8331 Valid Rcl (W): 0.8340 Valid F1 (W): 0.8319\n",
            "Performance improved... (0.8333309031555245->0.8344214594250654)\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4849 Train Acc (M): 0.7456 Train Prc (M): 0.8355 Train Rcl (M): 0.8348 Train F1 (M): 0.8341 Train Acc (W): 0.7356 Train Prc (W): 0.8276 Train Rcl (W): 0.8297 Train F1 (W): 0.8275 \n",
            "Valid Loss: 0.4677 Valid Acc (M): 0.7377 Valid Prc (M): 0.8393 Valid Rcl (M): 0.8377 Valid F1 (M): 0.8304 Valid Acc (W): 0.7380 Valid Prc (W): 0.8407 Valid Rcl (W): 0.8356 Valid F1 (W): 0.8299\n",
            "\n",
            "K-FOLD VALIDATION RESULTS: \n",
            "Accuracy: 0.76971915179794\n",
            "Precision: 0.8587198301592611\n",
            "Recall: 0.855303355901418\n",
            "F1: 0.8548700500833131\n",
            "\n",
            "VALIDATION RESULTS (PER CLASS): \n",
            "\n",
            "Accuracy:\n",
            "   climbing_down: 0.4954823129855564\n",
            "   climbing_up: 0.4855316958710142\n",
            "   jumping: 0.9209394692153314\n",
            "   lying: 0.9726033101081748\n",
            "   running: 0.9687041052168169\n",
            "   sitting: 0.9004420608401418\n",
            "   standing: 0.7962929595267298\n",
            "   walking: 0.6177573006197548\n",
            "\n",
            "Precision:\n",
            "   climbing_down: 0.6974363549937362\n",
            "   climbing_up: 0.707808488125953\n",
            "   jumping: 0.9587785917785917\n",
            "   lying: 0.9977235451104447\n",
            "   running: 0.9965043506252934\n",
            "   sitting: 0.9376878362505604\n",
            "   standing: 0.852712836120318\n",
            "   walking: 0.7211066382691907\n",
            "\n",
            "Recall:\n",
            "   climbing_down: 0.6334838772338772\n",
            "   climbing_up: 0.60986856516977\n",
            "   jumping: 0.9578347578347579\n",
            "   lying: 0.9747787332873017\n",
            "   running: 0.9720097402597402\n",
            "   sitting: 0.9577193298504774\n",
            "   standing: 0.9232029795158289\n",
            "   walking: 0.8135288640595905\n",
            "\n",
            "F1:\n",
            "   climbing_down: 0.661350929902965\n",
            "   climbing_up: 0.6520361319609207\n",
            "   jumping: 0.9580371287363517\n",
            "   lying: 0.9860633122716255\n",
            "   running: 0.9840741599155252\n",
            "   sitting: 0.947537127689043\n",
            "   standing: 0.8864632650811741\n",
            "   walking: 0.7633983451088997\n",
            "\n",
            "GENERALIZATION GAP ANALYSIS: \n",
            "\n",
            "Accuracy: [-0.20189951 -0.1807138  -0.37089336 -0.3587777  -0.3552771  -0.32542225\n",
            " -0.28760894 -0.24597153]\n",
            "Precision: [-0.26066491 -0.25412265 -0.38354432 -0.34089437 -0.33556713 -0.3091245\n",
            " -0.28697607 -0.24852526]\n",
            "Recall: [-0.23553571 -0.19845431 -0.37357035 -0.33133047 -0.32772225 -0.31829425\n",
            " -0.30916445 -0.29543066]\n",
            "F1: [-0.24495469 -0.22058176 -0.37835581 -0.33599498 -0.33157018 -0.31359095\n",
            " -0.29756738 -0.26915984]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "# number of splits, i.e. folds\n",
        "config['splits_kfold'] = 10\n",
        "\n",
        "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
        "seed_torch(config['seed'])\n",
        "\n",
        "# needed for saving results\n",
        "log_date = time.strftime('%Y%m%d')\n",
        "log_timestamp = time.strftime('%H%M%S')\n",
        "\n",
        "# define the stratified k-fold object; it is already imported for you\n",
        "# pass it the number of splits, i.e. folds, and seed as well as set shuffling to true\n",
        "skf = StratifiedKFold(n_splits=config['splits_kfold'],shuffle = True, random_state=config['seed'])\n",
        "    \n",
        "print(train_valid_data.shape)\n",
        "\n",
        "# apply the sliding window on top of both the train_valid_data; use the \"apply_sliding_window\" function\n",
        "# found in data_processing.sliding_window\n",
        "X_train_valid, y_train_valid = apply_sliding_window(train_valid_data[:, :-1], train_valid_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
        "\n",
        "print(X_train_valid.shape, y_train_valid.shape)\n",
        "\n",
        "# (optional) omit the first feature column (subject_identifier) from the train _valid_data\n",
        "# you can do it if you want to as it is not a useful feature\n",
        "X_train_valid = X_train_valid[:, :, 1:]\n",
        "\n",
        "# result objects used for accumulating the scores across folds; add each fold result to these objects so that they\n",
        "# are averaged at the end of the k-fold loop\n",
        "kfold_accuracy = np.zeros(config['nb_classes'])\n",
        "kfold_precision = np.zeros(config['nb_classes'])\n",
        "kfold_recall = np.zeros(config['nb_classes'])\n",
        "kfold_f1 = np.zeros(config['nb_classes'])\n",
        "    \n",
        "kfold_accuracy_gap = 0\n",
        "kfold_precision_gap = 0\n",
        "kfold_recall_gap = 0\n",
        "kfold_f1_gap = 0\n",
        "\n",
        "# k-fold validation loop; for each loop iteration return fold identifier and indeces which can be used to split\n",
        "# the train + valid data into train and validation data according to the current fold\n",
        "for j, (train_index, valid_index) in enumerate(skf.split(X_train_valid, y_train_valid)):\n",
        "    print('\\nFold {0}/{1}'.format(j + 1, config['splits_kfold']))\n",
        "    \n",
        "    # split the data into train and validation data; to do so, use the indeces produces by the split function\n",
        "    X_train, X_valid = X_train_valid[train_index], X_train_valid[valid_index]\n",
        "    y_train, y_valid = y_train_valid[train_index], y_train_valid[valid_index]\n",
        "    \n",
        "    # within the config file, set the parameters 'window_size' and 'nb_channels' accordingly\n",
        "    # window_size = size of the sliding window in units\n",
        "    # nb_channels = number of feature channels\n",
        "    config['window_size'] = X_train.shape[1]\n",
        "    config['nb_channels'] = X_train.shape[2]\n",
        "    \n",
        "    # define the network to be a DeepConvLSTM object; can be imported from model.DeepConvLSTM\n",
        "    # pass it the config object\n",
        "    net = DeepConvLSTM(config=config)\n",
        "    \n",
        "    # defines the loss and optimizer\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "\n",
        "    # convert the features of the train and validation to float32 and labels to uint8 for GPU compatibility \n",
        "    X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
        "    X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
        "    \n",
        "    # feed the datasets into the train function; can be imported from model.train\n",
        "    kfold_net, _, val_output, train_output = train(X_train, y_train, X_valid, y_valid, network=net, optimizer=opt, loss=loss, config=config, log_date=log_date, log_timestamp=log_timestamp)\n",
        "        \n",
        "    # in the following validation and train evaluation metrics are calculated\n",
        "    cls = np.array(range(config['nb_classes']))\n",
        "    val_accuracy = jaccard_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
        "    val_precision = precision_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
        "    val_recall = recall_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
        "    val_f1 = f1_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
        "    train_accuracy = jaccard_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
        "    train_precision = precision_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
        "    train_recall = recall_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
        "    train_f1 = f1_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
        "    \n",
        "    # add up the fold results\n",
        "    kfold_accuracy += val_accuracy\n",
        "    kfold_precision += val_precision\n",
        "    kfold_recall += val_recall\n",
        "    kfold_f1 += val_f1\n",
        "\n",
        "    # add up the generalization gap results\n",
        "    kfold_accuracy_gap += train_accuracy - val_accuracy\n",
        "    kfold_precision_gap += train_precision - val_precision\n",
        "    kfold_recall_gap += train_recall - val_recall\n",
        "    kfold_f1_gap += train_f1 - val_f1\n",
        "    \n",
        "# the next bit prints out the average results across folds if you did everything correctly\n",
        "print(\"\\nK-FOLD VALIDATION RESULTS: \")\n",
        "print(\"Accuracy: {0}\".format(np.mean(kfold_accuracy / config['splits_kfold'])))\n",
        "print(\"Precision: {0}\".format(np.mean(kfold_precision / config['splits_kfold'])))\n",
        "print(\"Recall: {0}\".format(np.mean(kfold_recall / config['splits_kfold'])))\n",
        "print(\"F1: {0}\".format(np.mean(kfold_f1 / config['splits_kfold'])))\n",
        "    \n",
        "print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
        "print(\"\\nAccuracy:\")\n",
        "for i, rslt in enumerate(kfold_accuracy / config['splits_kfold']):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "print(\"\\nPrecision:\")\n",
        "for i, rslt in enumerate(kfold_precision / config['splits_kfold']):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "print(\"\\nRecall:\")\n",
        "for i, rslt in enumerate(kfold_recall / config['splits_kfold']):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "print(\"\\nF1:\")\n",
        "for i, rslt in enumerate(kfold_f1 / config['splits_kfold']):\n",
        "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "    \n",
        "print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
        "print(\"\\nAccuracy: {0}\".format(kfold_accuracy_gap / config['splits_kfold']))\n",
        "print(\"Precision: {0}\".format(kfold_precision_gap / config['splits_kfold']))\n",
        "print(\"Recall: {0}\".format(kfold_recall_gap / config['splits_kfold']))\n",
        "print(\"F1: {0}\".format(kfold_f1_gap / config['splits_kfold']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI5ztrFyl9BL"
      },
      "source": [
        "### 5.3.3. Cross-Participant Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgc5fBYMl9BL"
      },
      "source": [
        "Cross-participant cross-validation, also known as Leave-One-Subject-Out (LOSO) cross-validation is the most complex, but also most expressive validation method one can apply when dealing with multi-subject data. In general, it can be seen as a variation of the k-fold cross-validation with k being the number of subjects. Within each fold, you train your network on the data of all but one subject and validate it on the left-out subject. The process is repeated as many times as there are subjects so that each subject becomes the validation set exaclty once. This way, each subject is treated as the unseen data at least once. \n",
        "\n",
        "Leaving one subject out each fold ensures that the overall evaluation of the algorithm does not overfit on subject-specific traits, i.e. how subjects performed the activities individually. It is therefore a great method to obtain a model which is good at predicting activities no matter which person performs them, i.e. a more general model!\n",
        "\n",
        "The next task will lead you through the implementation of the cross-participant cross-validation loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxmMLN71l9BM"
      },
      "source": [
        "#### Task 4: Implementing the cross-participant CV loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yaGaXanl9BM"
      },
      "source": [
        "1. Define a loop which iterates over the identifiers of all subjects. (`lines 8-10`)\n",
        "2. Define the `train` data to be everything but the current subject's data and the `valid` data to be the current subject's data by filtering the `train_valid_data`. (`lines 12-15`)\n",
        "3. Apply the `apply_sliding_window()` function on top of the filtered datasets you just defined. (`lines 19-27`)\n",
        "4. (*Optional*) Omit the first feature column (subject_identifier) from the train and validation dataset. (`lines 29-31`)\n",
        "5. Within the `config` object, set the parameters `window_size` and `nb_channels` accordingly. (`lines 51-55`)\n",
        "6. Define the `DeepConvLSTM` object. It is already imported for you. Also define the `optimizer` being the [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and `criterion` being the [Cross-Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (`lines 39-45`)\n",
        "7. Convert the feature columns of the train and validation to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 47-49`)\n",
        "8. Use both datasets to run the `train()` function. (`lines 51-52`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vcUekkJal9BM",
        "outputId": "bbba56b7-5cac-4f3c-b5ad-d0dd5791e44e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " VALIDATING FOR SUBJECT 1 OF 2\n",
            "(208835, 5) (221621, 5)\n",
            "(5966, 50, 4) (5966,)\n",
            "(6331, 50, 4) (6331,)\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0518, 1.0386, 5.4434, 0.8408, 0.8513, 0.8455, 0.8484, 0.8494])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.8490 Train Acc (M): 0.2033 Train Prc (M): 0.3057 Train Rcl (M): 0.3161 Train F1 (M): 0.3064 Train Acc (W): 0.2296 Train Prc (W): 0.3431 Train Rcl (W): 0.3478 Train F1 (W): 0.3420 \n",
            "Valid Loss: 1.3688 Valid Acc (M): 0.4112 Valid Prc (M): 0.6398 Valid Rcl (M): 0.5291 Valid F1 (M): 0.5020 Valid Acc (W): 0.4693 Valid Prc (W): 0.6117 Valid Rcl (W): 0.6065 Valid F1 (W): 0.5716\n",
            "Performance improved... (0.0->0.5019918045331558)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 1.0758 Train Acc (M): 0.4521 Train Prc (M): 0.5615 Train Rcl (M): 0.5902 Train F1 (M): 0.5633 Train Acc (W): 0.4936 Train Prc (W): 0.6117 Train Rcl (W): 0.5964 Train F1 (W): 0.5992 \n",
            "Valid Loss: 1.1178 Valid Acc (M): 0.3335 Valid Prc (M): 0.5967 Valid Rcl (M): 0.4929 Valid F1 (M): 0.4507 Valid Acc (W): 0.3651 Valid Prc (W): 0.6074 Valid Rcl (W): 0.5489 Valid F1 (W): 0.4866\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.7480 Train Acc (M): 0.5922 Train Prc (M): 0.6904 Train Rcl (M): 0.7223 Train F1 (M): 0.7005 Train Acc (W): 0.6239 Train Prc (W): 0.7261 Train Rcl (W): 0.7226 Train F1 (W): 0.7222 \n",
            "Valid Loss: 1.0781 Valid Acc (M): 0.3114 Valid Prc (M): 0.4754 Valid Rcl (M): 0.4792 Valid F1 (M): 0.4292 Valid Acc (W): 0.3340 Valid Prc (W): 0.4748 Valid Rcl (W): 0.5249 Valid F1 (W): 0.4534\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6154 Train Acc (M): 0.6696 Train Prc (M): 0.7576 Train Rcl (M): 0.7743 Train F1 (M): 0.7648 Train Acc (W): 0.6831 Train Prc (W): 0.7721 Train Rcl (W): 0.7732 Train F1 (W): 0.7721 \n",
            "Valid Loss: 1.0617 Valid Acc (M): 0.3095 Valid Prc (M): 0.5985 Valid Rcl (M): 0.4694 Valid F1 (M): 0.4251 Valid Acc (W): 0.3364 Valid Prc (W): 0.6052 Valid Rcl (W): 0.5211 Valid F1 (W): 0.4553\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5698 Train Acc (M): 0.7007 Train Prc (M): 0.7867 Train Rcl (M): 0.7993 Train F1 (M): 0.7921 Train Acc (W): 0.7092 Train Prc (W): 0.7966 Train Rcl (W): 0.7975 Train F1 (W): 0.7965 \n",
            "Valid Loss: 1.0134 Valid Acc (M): 0.4680 Valid Prc (M): 0.6469 Valid Rcl (M): 0.5916 Valid F1 (M): 0.5778 Valid Acc (W): 0.5120 Valid Prc (W): 0.6794 Valid Rcl (W): 0.6484 Valid F1 (W): 0.6205\n",
            "Performance improved... (0.5019918045331558->0.5777980829351383)\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5352 Train Acc (M): 0.7143 Train Prc (M): 0.7988 Train Rcl (M): 0.8070 Train F1 (M): 0.8024 Train Acc (W): 0.7203 Train Prc (W): 0.8052 Train Rcl (W): 0.8062 Train F1 (W): 0.8054 \n",
            "Valid Loss: 1.1448 Valid Acc (M): 0.3758 Valid Prc (M): 0.5696 Valid Rcl (M): 0.5143 Valid F1 (M): 0.4939 Valid Acc (W): 0.4092 Valid Prc (W): 0.5921 Valid Rcl (W): 0.5647 Valid F1 (W): 0.5288\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5173 Train Acc (M): 0.7232 Train Prc (M): 0.8086 Train Rcl (M): 0.8161 Train F1 (M): 0.8115 Train Acc (W): 0.7288 Train Prc (W): 0.8142 Train Rcl (W): 0.8158 Train F1 (W): 0.8143 \n",
            "Valid Loss: 1.0760 Valid Acc (M): 0.4385 Valid Prc (M): 0.6220 Valid Rcl (M): 0.5662 Valid F1 (M): 0.5574 Valid Acc (W): 0.4734 Valid Prc (W): 0.6579 Valid Rcl (W): 0.6069 Valid F1 (W): 0.5907\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.4876 Train Acc (M): 0.7420 Train Prc (M): 0.8267 Train Rcl (M): 0.8307 Train F1 (M): 0.8274 Train Acc (W): 0.7463 Train Prc (W): 0.8307 Train Rcl (W): 0.8307 Train F1 (W): 0.8295 \n",
            "Valid Loss: 1.0882 Valid Acc (M): 0.4303 Valid Prc (M): 0.6532 Valid Rcl (M): 0.5529 Valid F1 (M): 0.5458 Valid Acc (W): 0.4678 Valid Prc (W): 0.6634 Valid Rcl (W): 0.6065 Valid F1 (W): 0.5826\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4628 Train Acc (M): 0.7623 Train Prc (M): 0.8447 Train Rcl (M): 0.8445 Train F1 (M): 0.8438 Train Acc (W): 0.7627 Train Prc (W): 0.8442 Train Rcl (W): 0.8453 Train F1 (W): 0.8439 \n",
            "Valid Loss: 1.0785 Valid Acc (M): 0.4450 Valid Prc (M): 0.6666 Valid Rcl (M): 0.5651 Valid F1 (M): 0.5601 Valid Acc (W): 0.4797 Valid Prc (W): 0.6686 Valid Rcl (W): 0.6154 Valid F1 (W): 0.5922\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4694 Train Acc (M): 0.7571 Train Prc (M): 0.8405 Train Rcl (M): 0.8412 Train F1 (M): 0.8399 Train Acc (W): 0.7601 Train Prc (W): 0.8419 Train Rcl (W): 0.8431 Train F1 (W): 0.8415 \n",
            "Valid Loss: 1.0915 Valid Acc (M): 0.4286 Valid Prc (M): 0.6319 Valid Rcl (M): 0.5638 Valid F1 (M): 0.5574 Valid Acc (W): 0.4589 Valid Prc (W): 0.6638 Valid Rcl (W): 0.6005 Valid F1 (W): 0.5863\n",
            "\n",
            "VALIDATION RESULTS FOR SUBJECT 1: \n",
            "\n",
            "Avg. Accuracy: 0.467982254144728\n",
            "Avg. Precision: 0.6469171988995974\n",
            "Avg. Recall: 0.5916079253091346\n",
            "Avg. F1: 0.5777980829351383\n",
            "\n",
            "VALIDATION RESULTS (PER CLASS): \n",
            "\n",
            "Accuracy:\n",
            "   climbing_down: 0.129064039408867\n",
            "   climbing_up: 0.3395504543280727\n",
            "   jumping: 0.18125\n",
            "   lying: 0.9543429844097996\n",
            "   running: 0.6976744186046512\n",
            "   sitting: 0.7629268292682927\n",
            "   standing: 0.5783298826777088\n",
            "   walking: 0.10071942446043165\n",
            "\n",
            "Precision:\n",
            "   climbing_down: 0.3119047619047619\n",
            "   climbing_up: 0.38110574342458403\n",
            "   jumping: 0.4461538461538462\n",
            "   lying: 1.0\n",
            "   running: 0.9028727770177839\n",
            "   sitting: 0.9009216589861752\n",
            "   standing: 0.6121256391526662\n",
            "   walking: 0.620253164556962\n",
            "\n",
            "Recall:\n",
            "   climbing_down: 0.18044077134986225\n",
            "   climbing_up: 0.7569296375266524\n",
            "   jumping: 0.23387096774193547\n",
            "   lying: 0.9543429844097996\n",
            "   running: 0.7542857142857143\n",
            "   sitting: 0.832800851970181\n",
            "   standing: 0.9128540305010894\n",
            "   walking: 0.10733844468784227\n",
            "\n",
            "F1:\n",
            "   climbing_down: 0.22862129144851656\n",
            "   climbing_up: 0.5069617993573724\n",
            "   jumping: 0.3068783068783069\n",
            "   lying: 0.9766381766381768\n",
            "   running: 0.8219178082191781\n",
            "   sitting: 0.8655229662423908\n",
            "   standing: 0.7328377787494534\n",
            "   walking: 0.1830065359477124\n",
            "\n",
            "GENERALIZATION GAP ANALYSIS: \n",
            "\n",
            "Train-Val-Accuracy Difference: -0.4012750064740672\n",
            "Train-Val-Precision Difference: -0.5224376696227777\n",
            "Train-Val-Recall Difference: -0.46746631044749765\n",
            "Train-Val-F1 Difference: -0.45358197781306053\n",
            "\n",
            " VALIDATING FOR SUBJECT 2 OF 2\n",
            "(221621, 5) (208835, 5)\n",
            "(6331, 50, 4) (6331,)\n",
            "(5966, 50, 4) (5966,)\n",
            "+----------------------------+------------+\n",
            "|          Modules           | Parameters |\n",
            "+----------------------------+------------+\n",
            "| conv_blocks.0.conv1.weight |    704     |\n",
            "|  conv_blocks.0.conv1.bias  |     64     |\n",
            "| conv_blocks.0.conv2.weight |   45056    |\n",
            "|  conv_blocks.0.conv2.bias  |     64     |\n",
            "| conv_blocks.1.conv1.weight |   45056    |\n",
            "|  conv_blocks.1.conv1.bias  |     64     |\n",
            "| conv_blocks.1.conv2.weight |   45056    |\n",
            "|  conv_blocks.1.conv2.bias  |     64     |\n",
            "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
            "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
            "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
            "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
            "|         fc.weight          |    1024    |\n",
            "|          fc.bias           |     8      |\n",
            "+----------------------------+------------+\n",
            "Total Params: 302024\n",
            "Applied weighted class weights: \n",
            "tensor([1.0900, 0.8437, 6.3821, 0.8813, 0.9044, 0.8428, 0.8621, 0.8668])\n",
            "EPOCH: 1/10 \n",
            "Train Loss: 1.9617 Train Acc (M): 0.1190 Train Prc (M): 0.2434 Train Rcl (M): 0.2571 Train F1 (M): 0.2031 Train Acc (W): 0.1293 Train Prc (W): 0.2700 Train Rcl (W): 0.2203 Train F1 (W): 0.2194 \n",
            "Valid Loss: 1.3782 Valid Acc (M): 0.3219 Valid Prc (M): 0.4320 Valid Rcl (M): 0.5101 Valid F1 (M): 0.4150 Valid Acc (W): 0.3494 Valid Prc (W): 0.4772 Valid Rcl (W): 0.4744 Valid F1 (W): 0.4384\n",
            "Performance improved... (0.0->0.4149874219410226)\n",
            "EPOCH: 2/10 \n",
            "Train Loss: 1.1817 Train Acc (M): 0.4187 Train Prc (M): 0.5249 Train Rcl (M): 0.5741 Train F1 (M): 0.5389 Train Acc (W): 0.4342 Train Prc (W): 0.5491 Train Rcl (W): 0.5525 Train F1 (W): 0.5485 \n",
            "Valid Loss: 1.2095 Valid Acc (M): 0.3702 Valid Prc (M): 0.4391 Valid Rcl (M): 0.5518 Valid F1 (M): 0.4242 Valid Acc (W): 0.4201 Valid Prc (W): 0.4983 Valid Rcl (W): 0.5178 Valid F1 (W): 0.4698\n",
            "Performance improved... (0.4149874219410226->0.4241968861572333)\n",
            "EPOCH: 3/10 \n",
            "Train Loss: 0.7928 Train Acc (M): 0.5927 Train Prc (M): 0.6997 Train Rcl (M): 0.7265 Train F1 (M): 0.7100 Train Acc (W): 0.5902 Train Prc (W): 0.7053 Train Rcl (W): 0.7054 Train F1 (W): 0.7040 \n",
            "Valid Loss: 1.0357 Valid Acc (M): 0.4162 Valid Prc (M): 0.6178 Valid Rcl (M): 0.6061 Valid F1 (M): 0.4905 Valid Acc (W): 0.4685 Valid Prc (W): 0.6950 Valid Rcl (W): 0.5776 Valid F1 (W): 0.5388\n",
            "Performance improved... (0.4241968861572333->0.49053142945491796)\n",
            "EPOCH: 4/10 \n",
            "Train Loss: 0.6499 Train Acc (M): 0.6926 Train Prc (M): 0.7937 Train Rcl (M): 0.8005 Train F1 (M): 0.7960 Train Acc (W): 0.6760 Train Prc (W): 0.7843 Train Rcl (W): 0.7852 Train F1 (W): 0.7835 \n",
            "Valid Loss: 1.2404 Valid Acc (M): 0.3914 Valid Prc (M): 0.5183 Valid Rcl (M): 0.5807 Valid F1 (M): 0.4505 Valid Acc (W): 0.4407 Valid Prc (W): 0.5813 Valid Rcl (W): 0.5461 Valid F1 (W): 0.4938\n",
            "EPOCH: 5/10 \n",
            "Train Loss: 0.5775 Train Acc (M): 0.7320 Train Prc (M): 0.8286 Train Rcl (M): 0.8290 Train F1 (M): 0.8280 Train Acc (W): 0.7136 Train Prc (W): 0.8154 Train Rcl (W): 0.8169 Train F1 (W): 0.8152 \n",
            "Valid Loss: 1.2464 Valid Acc (M): 0.4007 Valid Prc (M): 0.5628 Valid Rcl (M): 0.5871 Valid F1 (M): 0.4576 Valid Acc (W): 0.4508 Valid Prc (W): 0.6312 Valid Rcl (W): 0.5521 Valid F1 (W): 0.5009\n",
            "EPOCH: 6/10 \n",
            "Train Loss: 0.5321 Train Acc (M): 0.7495 Train Prc (M): 0.8438 Train Rcl (M): 0.8411 Train F1 (M): 0.8417 Train Acc (W): 0.7298 Train Prc (W): 0.8294 Train Rcl (W): 0.8299 Train F1 (W): 0.8288 \n",
            "Valid Loss: 1.2780 Valid Acc (M): 0.4158 Valid Prc (M): 0.6051 Valid Rcl (M): 0.5988 Valid F1 (M): 0.4820 Valid Acc (W): 0.4682 Valid Prc (W): 0.6777 Valid Rcl (W): 0.5672 Valid F1 (W): 0.5288\n",
            "EPOCH: 7/10 \n",
            "Train Loss: 0.5002 Train Acc (M): 0.7661 Train Prc (M): 0.8587 Train Rcl (M): 0.8549 Train F1 (M): 0.8557 Train Acc (W): 0.7482 Train Prc (W): 0.8456 Train Rcl (W): 0.8455 Train F1 (W): 0.8443 \n",
            "Valid Loss: 1.3070 Valid Acc (M): 0.4166 Valid Prc (M): 0.6178 Valid Rcl (M): 0.6043 Valid F1 (M): 0.4815 Valid Acc (W): 0.4675 Valid Prc (W): 0.6907 Valid Rcl (W): 0.5711 Valid F1 (W): 0.5259\n",
            "EPOCH: 8/10 \n",
            "Train Loss: 0.4721 Train Acc (M): 0.7795 Train Prc (M): 0.8696 Train Rcl (M): 0.8640 Train F1 (M): 0.8656 Train Acc (W): 0.7629 Train Prc (W): 0.8566 Train Rcl (W): 0.8561 Train F1 (W): 0.8551 \n",
            "Valid Loss: 1.3506 Valid Acc (M): 0.4130 Valid Prc (M): 0.6194 Valid Rcl (M): 0.6017 Valid F1 (M): 0.4751 Valid Acc (W): 0.4633 Valid Prc (W): 0.6933 Valid Rcl (W): 0.5674 Valid F1 (W): 0.5185\n",
            "EPOCH: 9/10 \n",
            "Train Loss: 0.4541 Train Acc (M): 0.7806 Train Prc (M): 0.8705 Train Rcl (M): 0.8650 Train F1 (M): 0.8666 Train Acc (W): 0.7643 Train Prc (W): 0.8578 Train Rcl (W): 0.8574 Train F1 (W): 0.8563 \n",
            "Valid Loss: 1.4210 Valid Acc (M): 0.4078 Valid Prc (M): 0.6038 Valid Rcl (M): 0.5946 Valid F1 (M): 0.4690 Valid Acc (W): 0.4579 Valid Prc (W): 0.6764 Valid Rcl (W): 0.5597 Valid F1 (W): 0.5123\n",
            "EPOCH: 10/10 \n",
            "Train Loss: 0.4444 Train Acc (M): 0.7907 Train Prc (M): 0.8791 Train Rcl (M): 0.8718 Train F1 (M): 0.8742 Train Acc (W): 0.7742 Train Prc (W): 0.8657 Train Rcl (W): 0.8648 Train F1 (W): 0.8639 \n",
            "Valid Loss: 1.5010 Valid Acc (M): 0.3958 Valid Prc (M): 0.5742 Valid Rcl (M): 0.5834 Valid F1 (M): 0.4545 Valid Acc (W): 0.4440 Valid Prc (W): 0.6438 Valid Rcl (W): 0.5459 Valid F1 (W): 0.4957\n",
            "\n",
            "VALIDATION RESULTS FOR SUBJECT 2: \n",
            "\n",
            "Avg. Accuracy: 0.41620942770671787\n",
            "Avg. Precision: 0.6178175323867823\n",
            "Avg. Recall: 0.6060881661079085\n",
            "Avg. F1: 0.49053142945491796\n",
            "\n",
            "VALIDATION RESULTS (PER CLASS): \n",
            "\n",
            "Accuracy:\n",
            "   climbing_down: 0.2498580352072686\n",
            "   climbing_up: 0.03543307086614173\n",
            "   jumping: 0.12583412774070543\n",
            "   lying: 0.9797752808988764\n",
            "   running: 0.0193621867881549\n",
            "   sitting: 0.8322147651006712\n",
            "   standing: 0.8583247156153051\n",
            "   walking: 0.22887323943661972\n",
            "\n",
            "Precision:\n",
            "   climbing_down: 0.2949061662198391\n",
            "   climbing_up: 0.38028169014084506\n",
            "   jumping: 0.12643678160919541\n",
            "   lying: 0.9965714285714286\n",
            "   running: 0.8947368421052632\n",
            "   sitting: 0.8435374149659864\n",
            "   standing: 0.9041394335511983\n",
            "   walking: 0.5019305019305019\n",
            "\n",
            "Recall:\n",
            "   climbing_down: 0.6205923836389281\n",
            "   climbing_up: 0.037604456824512536\n",
            "   jumping: 0.9635036496350365\n",
            "   lying: 0.9830890642615558\n",
            "   running: 0.019406392694063926\n",
            "   sitting: 0.9841269841269841\n",
            "   standing: 0.944254835039818\n",
            "   walking: 0.296127562642369\n",
            "\n",
            "F1:\n",
            "   climbing_down: 0.3998182644252612\n",
            "   climbing_up: 0.06844106463878327\n",
            "   jumping: 0.2235393734123624\n",
            "   lying: 0.9897843359818389\n",
            "   running: 0.03798882681564245\n",
            "   sitting: 0.9084249084249083\n",
            "   standing: 0.9237618252643295\n",
            "   walking: 0.37249283667621774\n",
            "\n",
            "GENERALIZATION GAP ANALYSIS: \n",
            "\n",
            "Train-Val-Accuracy Difference: -0.3459914422033155\n",
            "Train-Val-Precision Difference: -0.48700339593107156\n",
            "Train-Val-Recall Difference: -0.47619742944420773\n",
            "Train-Val-F1 Difference: -0.36045417939554214\n"
          ]
        }
      ],
      "source": [
        "# needed for saving results\n",
        "log_date = time.strftime('%Y%m%d')\n",
        "log_timestamp = time.strftime('%H%M%S')\n",
        "\n",
        "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
        "seed_torch(config['seed'])\n",
        "\n",
        "# iterate over all subjects\n",
        "for i, sbj in enumerate(np.unique(train_valid_data[:, 0])):\n",
        "    print('\\n VALIDATING FOR SUBJECT {0} OF {1}'.format(int(sbj) + 1, int(np.max(train_valid_data[:, 0])) + 1))\n",
        "    \n",
        "    # define the train data to be everything, but the data of the current subject\n",
        "    train_data = train_valid_data[train_valid_data[:, 0] != sbj]\n",
        "    # define the validation data to be the data of the current subject\n",
        "    valid_data = train_valid_data[train_valid_data[:, 0] == sbj]\n",
        "    \n",
        "    print(train_data.shape, valid_data.shape)\n",
        "    \n",
        "    # apply the sliding window on top of both the train and validation data; use the \"apply_sliding_window\" function\n",
        "    # found in data_processing.sliding_window\n",
        "    X_train, y_train = apply_sliding_window(train_data[:, :-1], train_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
        "\n",
        "    print(X_train.shape, y_train.shape)\n",
        "\n",
        "    X_valid, y_valid = apply_sliding_window(valid_data[:, :-1], valid_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
        "\n",
        "    print(X_valid.shape, y_valid.shape)\n",
        "\n",
        "    # (optional) omit the first feature column (subject_identifier) from the train and validation dataset\n",
        "    # you can do it if you want to as it is not a useful feature\n",
        "    X_train, X_valid = X_train[:, :, 1:], X_valid[:, :, 1:]\n",
        "    \n",
        "    # within the config file, set the parameters 'window_size' and 'nb_channels' accordingly\n",
        "    # window_size = size of the sliding window in units\n",
        "    # nb_channels = number of feature channels\n",
        "    config['window_size'] = X_train.shape[1]\n",
        "    config['nb_channels'] = X_train.shape[2]\n",
        "    \n",
        "    # define the network to be a DeepConvLSTM object; can be imported from model.DeepConvLSTM\n",
        "    # pass it the config object\n",
        "    net = DeepConvLSTM(config=config)\n",
        "\n",
        "    # defines the loss and optimizer\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "\n",
        "    # convert the features of the train and validation to float32 and labels to uint8 for GPU compatibility \n",
        "    X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
        "    X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
        "    \n",
        "    # feed the datasets into the train function; can be imported from model.train\n",
        "    cross_participant_net, _, val_output, train_output = train(X_train, y_train, X_valid, y_valid, network=net, optimizer=opt, loss=loss, config=config, log_date=log_date, log_timestamp=log_timestamp)\n",
        "    \n",
        "    # the next bit prints out the average results per subject if you did everything correctly\n",
        "    cls = np.array(range(config['nb_classes']))\n",
        "    \n",
        "    print('\\nVALIDATION RESULTS FOR SUBJECT {0}: '.format(int(sbj) + 1))\n",
        "    print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "    print(\"Avg. Precision: {0}\".format(precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "    print(\"Avg. Recall: {0}\".format(recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "    print(\"Avg. F1: {0}\".format(f1_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "\n",
        "    print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
        "    print(\"\\nAccuracy:\")\n",
        "    for i, rslt in enumerate(jaccard_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "    print(\"\\nPrecision:\")\n",
        "    for i, rslt in enumerate(precision_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "    print(\"\\nRecall:\")\n",
        "    for i, rslt in enumerate(recall_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "    print(\"\\nF1:\")\n",
        "    for i, rslt in enumerate(f1_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
        "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
        "\n",
        "    print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
        "    print(\"\\nTrain-Val-Accuracy Difference: {0}\".format(jaccard_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                                      jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "    print(\"Train-Val-Precision Difference: {0}\".format(precision_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                                       precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "    print(\"Train-Val-Recall Difference: {0}\".format(recall_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                                    recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
        "    print(\"Train-Val-F1 Difference: {0}\".format(f1_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
        "                                                f1_score(val_output[:, 1], val_output[:, 0], average='macro')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTFNUytOl9BM"
      },
      "source": [
        "## 5.4 Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXvP175Tl9BM"
      },
      "source": [
        "Now, after having implemented each of the validation techniques we want to get an unbiased view of how our trained algorithm perfoms on unseen data. To do so we use the testing set which we split off the original dataset within the first step of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4cmr2Tll9BM"
      },
      "source": [
        "### Task 5: Testing your trained networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHRkzAaul9BM"
      },
      "source": [
        "1. Apply the `apply_sliding_window()` function on top of the `test` data. (`lines 7-9`)\n",
        "2. (*Optional*) Omit the first feature column (subject_identifier) from the test dataset. (`lines 12-14`)\n",
        "3. Convert the feature columns of the test dataset to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 17-18`)\n",
        "4. Using the `predict()` function of the DL-ARC GitHub to obtain results on the `test` data using each of the trained networks as input. The function is already imported for you. (`lines 20-29`)\n",
        "5. Which model does perform the best and why? Was this expected? Can you make out a reason why that is? \n",
        "6. What would you change about the pipeline we just created if your goal was to get the best predictions possible? Hint: think about the amount of data which actually trained your model in the end!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L9s6kwjul9BM",
        "outputId": "fad91a0b-c70b-46ff-a17c-8343e7aae11c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6536, 50, 4) (6536,)\n",
            "COMPILED TEST RESULTS: \n",
            "\n",
            "Test results (train-valid-split): \n",
            "\n",
            "TEST RESULTS: \n",
            "Avg. Accuracy: 0.06198352781685943\n",
            "Avg. Precision: 0.06608172921948667\n",
            "Avg. Recall: 0.23713688025099175\n",
            "Avg. F1: 0.08688312333720438\n",
            "\n",
            "TEST RESULTS (PER CLASS): \n",
            "Accuracy: [0.         0.         0.03008475 0.00104167 0.         0.46474181\n",
            " 0.         0.        ]\n",
            "Precision: [0.         0.         0.03011665 0.01694915 0.         0.48158803\n",
            " 0.         0.        ]\n",
            "Recall: [0.         0.         0.96598639 0.00110865 0.         0.93\n",
            " 0.         0.        ]\n",
            "F1: [0.         0.         0.05841218 0.00208117 0.         0.63457165\n",
            " 0.         0.        ]\n",
            "\n",
            "Test results (k-fold): \n",
            "\n",
            "TEST RESULTS: \n",
            "Avg. Accuracy: 0.07127394429859263\n",
            "Avg. Precision: 0.12414108852471475\n",
            "Avg. Recall: 0.18651329748455184\n",
            "Avg. F1: 0.09497152696210359\n",
            "\n",
            "TEST RESULTS (PER CLASS): \n",
            "Accuracy: [0.         0.         0.02920017 0.00077399 0.         0.54021739\n",
            " 0.         0.        ]\n",
            "Precision: [0.         0.         0.02925588 0.00255754 0.         0.96131528\n",
            " 0.         0.        ]\n",
            "Recall: [0.         0.         0.93877551 0.00110865 0.         0.55222222\n",
            " 0.         0.        ]\n",
            "F1: [0.         0.         0.05674342 0.00154679 0.         0.701482\n",
            " 0.         0.        ]\n",
            "\n",
            "Test results (cross-participant): \n",
            "\n",
            "TEST RESULTS: \n",
            "Avg. Accuracy: 0.02557808170443683\n",
            "Avg. Precision: 0.07408710520291605\n",
            "Avg. Recall: 0.15774358342870431\n",
            "Avg. F1: 0.048656467788911\n",
            "\n",
            "TEST RESULTS (PER CLASS): \n",
            "Accuracy: [0.         0.         0.03438257 0.0616559  0.05325815 0.05200946\n",
            " 0.00331858 0.        ]\n",
            "Precision: [0.         0.         0.03442424 0.11589404 0.14237856 0.1\n",
            " 0.2        0.        ]\n",
            "Recall: [0.         0.         0.96598639 0.11640798 0.07841328 0.09777778\n",
            " 0.00336323 0.        ]\n",
            "F1: [0.         0.         0.0664794  0.11615044 0.10113028 0.0988764\n",
            " 0.00661521 0.        ]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4, 4, 4, ..., 6, 6, 6]), array([1, 1, 1, ..., 5, 5, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from model.train import predict\n",
        "\n",
        "\n",
        "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
        "seed_torch(config['seed'])\n",
        "\n",
        "# apply the sliding window on top of both the test data; use the \"apply_sliding_window\" function\n",
        "# found in data_processing.sliding_window\n",
        "X_test, y_test = apply_sliding_window(test_data[:, :-1], test_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
        "\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "# (optional) omit the first feature column (subject_identifier) from the test dataset\n",
        "# you need to do it if you did so during training and validation!\n",
        "X_test = X_test[:, :, 1:]\n",
        "\n",
        "# convert the features of test to float32 and labels to uint8 for GPU compatibility \n",
        "X_test, y_test = X_test.astype(np.float32), y_test.astype(np.uint8)\n",
        "\n",
        "# the next lines will print out the test results for each of the trained networks\n",
        "print('COMPILED TEST RESULTS: ')\n",
        "print('\\nTest results (train-valid-split): ')\n",
        "predict(X_test, y_test, train_valid_net, config, log_date, log_timestamp)\n",
        "\n",
        "print('\\nTest results (k-fold): ')\n",
        "predict(X_test, y_test, kfold_net, config, log_date, log_timestamp)\n",
        "\n",
        "print('\\nTest results (cross-participant): ')\n",
        "predict(X_test, y_test, cross_participant_net, config, log_date, log_timestamp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zl6pmmirzDZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "validation_and_testing_solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}