{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "iSemvd0ljKHS"
   },
   "source": [
    "# 4. Network Architecture & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msYjbPfCjKHU"
   },
   "source": [
    "Welcome to the fourth notebook of our six part series part of our tutorial on Deep Learning for Human Activity Recognition. Within the last notebook you learned:\n",
    "\n",
    "- What are common evaluation metrics when evaluating the performance of an Human Activity Recognition model?\n",
    "- How are they defined? How are they computed? How do they differ from each other?\n",
    "\n",
    "This notebook will teach you everything you need to know about how neural networks are defined and trained using [PyTorch](https://pytorch.org/). As mentioned during the [theoretical part](https://https://mariusbock.github.io/dl-for-har/) of this session, we will not go into detail about each building block of a neural network and how a network is trained, but rather stick to a basic level of understanding. If you want to dig deeper, we recommend you checking out other sources, like [Coursera](https://www.coursera.org/courses?query=deep%20learning) and [YouTube](https://www.youtube.com/results?search_query=deep+learning), as there are plenty of well written tutorials on the fundamentals of Deep Learning. After working through this notebook you will be able to answer the following questions:\n",
    "\n",
    "- How do I define a sample neural network architecture in PyTorch? \n",
    "- What additional preprocessing do I need to apply to my data to fed it into my network?\n",
    "- How do I define a train loop which trains my neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9yp-QySq02H"
   },
   "source": [
    "## 4.1. Important Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwUayaWhq8Gu"
   },
   "source": [
    "If you are accessing this tutorial via [Google Colab](https://colab.research.google.com/github/mariusbock/dl-for-har/blob/main/tutorial_notebooks/training.ipynb), first make sure to use Google Colab in English. This will help us to better assist you with issues that might arise during the tutorial. There are two ways to change the default language if it isn't English already:\n",
    "1. On Google Colab, go to `Help` -> `View in English` \n",
    "2. Change the default language of your browser to `English`.\n",
    "\n",
    "To also ease the communication when communicating errors, enable line numbers within the settings of Colab.\n",
    "\n",
    "1. On Google Colab, go to `Tools` -> `Settings` -> `Editor` -> `Show line numbers`\n",
    "\n",
    "In general, we strongly advise you to use Google Colab as it provides you with a working Python distribution as well as free GPU resources. To make Colab use GPUs, you need to change the current notebooks runtime type via:\n",
    "\n",
    "- `Runtime` -> `Change runtime type` -> `Dropdown` -> `GPU` -> `Save`\n",
    "\n",
    "**Hint:** you can auto-complete code in Colab via `ctrl` + `spacebar`\n",
    "\n",
    "For the live tutorial, we require all participants to use Colab. If you decide to rerun the tutorial at later points and rather want to have it run locally on your machine, feel free to clone our [GitHub repository](https://github.com/mariusbock/dl-for-har).\n",
    "\n",
    "To get started with this notebook, you need to first run the code cell below. Please set `use_colab` to be `True` if you are accessing this notebook via Colab. If not, please set it to `False`. This code cell will make sure that imports from our GitHub repository will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rXaaTKSjKHV"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "use_colab = True\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if use_colab:\n",
    "    # move to content directory and remove directory for a clean start \n",
    "    %cd /content/         \n",
    "    %rm -rf dl-for-har\n",
    "    # clone package repository (will throw error if already cloned)\n",
    "    !git clone https://github.com/mariusbock/dl-for-har.git\n",
    "    # navigate to dl-for-har directory\n",
    "    %cd dl-for-har/       \n",
    "else:\n",
    "    os.chdir(module_path)\n",
    "    \n",
    "# this statement is needed so that we can use the methods of the DL-ARC pipeline\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09SQsOe6jKHV"
   },
   "source": [
    "## 4.2. Defining a Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWrCb-ypjKHW"
   },
   "source": [
    "During this tutorial we will use [PyTorch](https://pytorch.org/) as our Deep Learning framework of choice. The open source library is one of the most popular frameworks out there for applying Deep Learning. It has all the necessary building blocks found in neural networks pre-implemented as well as offers a variety of helpful functions which can be used to easily implement your first Deep Learning script with just a few lines of code.\n",
    "\n",
    "In the following we will define our neural network architecture. Once defined we can use our previously preprocessed sensor-data to train a network which will be able to predict the type of activities being performed for a given sliding window. \n",
    "\n",
    "As mentioned during the introduction to this chapter, the architecture which we will used is called **DeepConvLSTM** [[1]](#1). The architecture was introduced by Francisco Javier Ordonez and Daniel Roggen in 2016 and is to this date a state-of-the-art architecture for applying Deep Learning on Human Activity Recognition. The architecture combines both convolutional and recurrent layers.\n",
    "\n",
    "The architecture is made of three main parts:\n",
    "\n",
    "1. **Convolutional layers:** Convolutional layers are based on filters (e.g. a 2 by 1 matrix) shifting over some input (e.g. a sliding window) resulting in activation feature map. The main idea of convolutions is that they are able to detect a specific type of feature anywhere within the input. Within the original architecture Ordonez and Roggen apply 4 convolutional layers each with 64 filters of size 5 by 1. \n",
    "2. **LSTM layer(s):** After applying convolutional layers, Ordonez and Roggen make us of an LSTM in order to capture time dependencies on features extracted by convolutional operations. An LSTM is a type of neural network which is able to learn temporal dependencies in data via gated mechanisms. The LSTM itself is structured into layers. Within the original architecture Ordonez and Roggen employ a 2-layered LSTM with 128 hidden units. \n",
    "3. **Classification layer:** The output of the LSTM is finally fed into a classifier which is a fully-connected layer and produces the final predictions. Preceeding the classifier, Ordonez and Roggen additionally put a dropout layer, which is a form of regularization. A dropout layer randomly deactivates neurons according to a dropout probability and thus prevents the probability of your network overfitting.\n",
    "\n",
    "Contradicting to popular belief that one needs at least a 2-layered LSTM when dealing with sequential data, within a recent work of ours, we exhibited that a 1-layered LSTM might be a better suited option when dealing with raw sensor-data [[2]](#2). Therefore, within the next code block, we will define the altered DeepConvLSTM architecture as presented in our paper which **employs a 1-layered instead of 2-layered LSTM**.\n",
    "\n",
    "In order to give you a better idea of how to define your PyTorch implementation of the DeepConvLSTM, we already defined a [PyTorch module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) called **DeepConvLSTM** for you to start out with. A PyTorch module typically consists of two main functions - the `init()` and `forward()` function. Within the former all relevant parameters and building blocks of the neural network are defined. Within the latter the parameters and building blocks are put together, i.e. the computation of the network defined. Within the next tasks you will be asked to fill in some of the missing parts of said module function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPb2NTEZ7YA5"
   },
   "source": [
    "### Task 1: Implementing the DeepConvLSTM\n",
    "1. Within the `init()` function define the activation function. Use [PyTorch's implementation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) of the ReLU activation function called `ReLU`. Set `inplace=True`. (`lines 17-18`)\n",
    "2. Within the `init()` function define the four convolution layers. Use [PyTorch's implementation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) of a 2d-convolution called `Conv2d`. Hints on the input and dimensions are given as comments within the code. The filter size should be of size (`filter_width x 1`) (`lines 20-24`)\n",
    "3. Within the `init()` function define the LSTM. Use [PyTorch's implementation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) of a LSTM called `LSTM`. Hints on the input size of the LSTM is given as comments within the code. The `hidden_size` and `num_layers` are given as attributes within the `init()` function. (`lines 26-27`)\n",
    "4. Within the `init()` define the dropout layer. Use [PyTorch's implementation](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) of a dropout layer called `Dropout`. Pass the `Dropout` object the `drop_prob` variable defined within the `init()` function (`lines 29-30`)\n",
    "5. Within the `init()` define the classifier, i.e. fully connected layer. Use [PyTorch's implementation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) of a fully-connected layer called `Linear`. (`lines 32-33`)\n",
    "6. Fill in the blanks within the `forward()` function. Apply each of the building blocks you defined in the `init()` on your input `x`. (`lines 39-43, 52-53 and 58-60`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acRTdIHDjKHW"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class DeepConvLSTM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DeepConvLSTM, self).__init__()\n",
    "        # parameters\n",
    "        self.window_size = config['window_size']\n",
    "        self.drop_prob = config['drop_prob']\n",
    "        self.nb_channels = config['nb_channels']\n",
    "        self.nb_classes = config['nb_classes']\n",
    "        self.seed = config['seed']\n",
    "        self.nb_filters = config['nb_filters']\n",
    "        self.filter_width = config['filter_width']\n",
    "        self.nb_units_lstm = config['nb_units_lstm']\n",
    "        self.nb_layers_lstm = config['nb_layers_lstm']\n",
    "\n",
    "        # define activation function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # define conv layers\n",
    "        self.conv1 = nn.Conv2d(1, self.nb_filters, (self.filter_width, 1))\n",
    "        self.conv2 = nn.Conv2d(self.nb_filters, self.nb_filters, (self.filter_width, 1))\n",
    "        self.conv3 = nn.Conv2d(self.nb_filters, self.nb_filters, (self.filter_width, 1))\n",
    "        self.conv4 = nn.Conv2d(self.nb_filters, self.nb_filters, (self.filter_width, 1))\n",
    "        \n",
    "        # define lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=self.nb_filters * self.nb_channels, hidden_size=self.nb_units_lstm, num_layers=self.nb_layers_lstm)\n",
    "\n",
    "        # define dropout layer\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        \n",
    "        # define classifier\n",
    "        self.fc = nn.Linear(self.nb_units_lstm, self.nb_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # reshape data for convolutions\n",
    "        x = x.view(-1, 1, self.window_size, self.nb_channels)\n",
    "        \n",
    "        # apply convolution and the activation function\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        \n",
    "        # sets the final sequence length \n",
    "        final_seq_len = x.shape[2]\n",
    "        \n",
    "        # permute dimensions and reshape for LSTM\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape(-1, final_seq_len, self.nb_filters * self.nb_channels)\n",
    "\n",
    "        # apply LSTM (note: it has two outputs!)\n",
    "        x, _ = self.lstm(x)\n",
    "            \n",
    "        # reshape data for classifier\n",
    "        x = x.view(-1, self.nb_units_lstm)\n",
    "        \n",
    "        # apply dropout and feed data through classifier\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # reshape data and return predicted label of last sample within final sequence (determines label of window)\n",
    "        out = x.view(-1, final_seq_len, self.nb_classes)\n",
    "        return out[:, -1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k2G6nifjKHX"
   },
   "source": [
    "## 4.3. Preparing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j56XD_tJjKHX"
   },
   "source": [
    "Great, we now have a neural network defined which we can call and use for training! But, there is one essential step missing before moving on towards the training loop - your data needs to be put into the correct format (again). In addition to the preprocessing steps that you know from the previous notebook, we also need to **make sure that our dataset is using the correct data types which are compatible with a GPU**. Furthermore, our data needs to be split into a **training** and **validation** dataset. As you know from the [theoretical part of this section](https://mariusbock.github.io/dl-for-har), within Deep Learning we essentially try to approximate a function. To judge whether the parameterized function we came up with appropriately approximates such underlying function, we validate our network's perfomance on unseen data. If the algorithm still performs well, i.e. predicts the correct labels for the unseen data, we say that we have found a **generalized function**. The next notebook will cover in more detail what different validation methods exist and go into detail why we need and what common pitfalls exist.\n",
    "\n",
    "The following task will guide you through the necessary preprocessing one needs to apply on top of the [RealWorld (HAR) dataset](https://sensor.informatik.uni-mannheim.de/#dataset_realworld). The first step of loading the data will already be filled out for you. As you can see, we used a predefined method called `load_dataset()`, which is part of the DL-ARC feature stack.\n",
    "\n",
    "The preprocessing consists of **four essential parts**:\n",
    "\n",
    "1. Split the data into a training and validation dataset. The validation dataset is used to gain feedback on the perfomance of the model and functions as unseen data. Results obtained on the validation dataset can be used as an indicator whether the changes you make to a network and/ or its training process are improving or worsening results.\n",
    "2. Apply the sliding window approach on top of the training and validation dataset. As you learned in the previous notebook, we do not classify a single record, but a window of records. The label of the last record within a window defines the label of the window and is our ultimate goal to predict.\n",
    "3. (Optional) Omit the subject identifier column.\n",
    "4. Convert the two datasets into the correct data format so that they are compatible with the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OKmg7nmaWKv"
   },
   "source": [
    "### Task 2: Getting your data ready for training\n",
    "1. Split the data into a train and validation dataset. The train dataset shall consist of the data of the first two subjects. The validation dataset shall be the data of the third subject. (`lines 16-19`)\n",
    "2. Segment your train and validation data into windows. Instead of going back to your defined function within the last notebook, you can use our [predefined method](https://github.com/mariusbock/dl-for-har/blob/main/data_processing/sliding_window.py) which is part of the DL-ARC feature stack called `apply_sliding_window`. It is already imported for you. (`lines 26-29`)\n",
    "3. (*Optional*) Omit the first feature column (subject_identifier) from the train and validation dataset. (`lines 35-36`)\n",
    "4. Convert the feature columns of the train and validation to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 41-43`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWgC9soBjKHY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from data_processing.sliding_window import apply_sliding_window\n",
    "from data_processing.preprocess_data import load_dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# data loading (we are using a predefined method called load_dataset, which is part of the DL-ARC feature stack)\n",
    "X, y, num_classes, class_names, sampling_rate, has_null = load_dataset('rwhar_3sbjs', include_null=True)\n",
    "# since the method returns features and labels separatley, we need to concat them\n",
    "data = np.concatenate((X, y[:, None]), axis=1)\n",
    "\n",
    "# define the train data to be all data belonging to the first two subjects\n",
    "train_data = data[data[:, 0] <= 1]\n",
    "# define the validation data to be all data belonging to the third subject\n",
    "valid_data = data[data[:, 0] == 2]\n",
    "\n",
    "# settings for the sliding window (change them if you want to!)\n",
    "sw_length = 50\n",
    "sw_unit = 'units'\n",
    "sw_overlap = 50\n",
    "\n",
    "# apply a sliding window on top of both the train and validation data; you can use our predefined method\n",
    "# you can import it via from preprocessing.sliding_window import apply_sliding_window\n",
    "X_train, y_train = apply_sliding_window(train_data[:, :-1], train_data[:, -1], sliding_window_size=sw_length, unit=sw_unit, sampling_rate=50, sliding_window_overlap=sw_overlap)\n",
    "X_valid, y_valid = apply_sliding_window(valid_data[:, :-1], valid_data[:, -1], sliding_window_size=sw_length, unit=sw_unit, sampling_rate=50, sliding_window_overlap=sw_overlap)\n",
    "\n",
    "print(\"\\nShape of the train and validation datasets after splitting and windowing: \")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "# (optional) omit the first feature column (subject_identifier) from the train and validation dataset\n",
    "X_train, X_valid = X_train[:, :, 1:], X_valid[:, :, 1:]\n",
    "\n",
    "print(\"\\nShape of the train and validation feature dataset after splitting and windowing: \")\n",
    "print(X_train.shape, X_valid.shape)\n",
    "\n",
    "# convert the features of the train and validation to float32 and labels to uint8 for GPU compatibility \n",
    "X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBiCDiSDjKHY"
   },
   "source": [
    "## 4.4. Training Your Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNNnPX2_jKHZ"
   },
   "source": [
    "Since we now have brought the data into the correct format, let's train our network with it!\n",
    "\n",
    "A typical training loop can be divided into three steps:\n",
    "\n",
    "1. **Definition:** You define your network, optimizer and loss\n",
    "2. **Training:** Iterating over the number of epochs: you chunk your training data into so-called batches and iteratively feed them through your network. After a batch has been fed through the network, you compute the loss said batch produced. Using the loss you backprogate it through the network using the optimizer which adjusts the weights accordingly. \n",
    "3. **Validation:** After you have processed your whole training dataset, you go on to validate the predictive performance of the network. To do so you again chunk your training and validation data into batches. Iterating over all batches of both all datasets, fed the batches through the trained network and obtain its predictions. **Note:** you only want to obtain predictions and not backpropagate any loss. \n",
    "\n",
    "The obtained predictions can now be used to calculate standard evaluation metrics such as **precision** and **recall**. Due to being limited in time we will not talk about their computation in great detail during the tutorial. Nevertheless, we created a [separate notebook](https://colab.research.google.com/github/mariusbock/dl-for-har/blob/main/tutorial_notebooks/evaluation.ipynb) for you which covers the most essential evaluation metrics used in HAR. Feel free to work through it if you want to accustom yourself with how each of them is calculated. \n",
    "\n",
    "The next task will guide you through **implementing your training and validation loop**. It will again have parts missing which you need to fill out, but will already provide you with certain code segments, to ease the task and focus on the essential parts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcKPnZBpjKHZ"
   },
   "source": [
    "### Task 3: Define your own train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2qXFHVojKHZ"
   },
   "source": [
    "1. You'll see that we already defined a `config` object which you can use to pass to your network. Nevertheless, there are three values missing, namely the `window_size`, `nb_channels` and `nb_classes`. Define them correctly. (`lines 32-38`)\n",
    "2. Define your DeepConvLSTM network by calling the object we previously defined. Also define the `optimizer` being the [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and `criterion` being the [Cross-Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (`lines 40-41 and 47-49`)\n",
    "3. Define the `DataLoader` objects. The `DataLoader` objects only work with [PyTorch tensor datasets](https://pytorch.org/docs/stable/data.html), which we already defined for you as the `val_dataset` and `train_dataset`  variables. Pass the `DataLoader` object the dataset variables, the `batch_size` you want to use and set `shuffle=True`. (`lines 48-54`)\n",
    "4. Further define the training loop by iterating over the training `DataLoader` object. We already defined parts for you. In a nutshell: for each batch, compute the loss by passing it through the network; backprogate the computed loss using your optimizer object. Use the [.backward()](https://pytorch.org/docs/stable/autograd.html) of the loss object and [.step()](https://pytorch.org/docs/stable/optim.html) of the optimizer to do so. (`lines 74-75 and 80-83`)\n",
    "5. While training obtain predictions for the train dataset. To do so obtain the final predicitons for each batch by applying the PyTorch `softmax` [function](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) on top of the network output. (`lines 85-86`)\n",
    "6. After training obtain predictions for the validation dataset using the resulting trained network of the current epoch. Iterate again over the validation `DataLoader` object and fed each batch through the network. In addition to calculating the [cross-entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), obtain the final predicitons for each batch by applying the PyTorch `softmax` [function](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) on top of the network output. Using the predictions the script will calculate [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) and [F1-score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) on both your training and validation set. (`lines 118-119 and 124-125`)\n",
    "7. Play around with different values for the parameters within the `config` file. How does each one of them influence your training loop? Feel free to also use a completly different optimizer - you can find all the different options on the [PyTorch website](https://pytorch.org/docs/stable/optim.html). (`lines 12-27`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hqs2TL0jKHa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "import time\n",
    "from misc.torchutils import seed_torch\n",
    "\n",
    "\n",
    "# this is the config object which contains all relevant settings. Feel free to change them and see how it influences\n",
    "# your results. Parameters which shouldn't be changed are marked.\n",
    "config = {\n",
    "    'nb_filters': 64,\n",
    "    'filter_width': 11,\n",
    "    'nb_units_lstm': 128,\n",
    "    'nb_layers_lstm': 1,\n",
    "    'drop_prob': 0.5,\n",
    "    'seed': 1,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-6,\n",
    "    'gpu_name': 'cuda:0',\n",
    "    'print_counts': False\n",
    "}\n",
    "\n",
    "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
    "seed_torch(config['seed'])\n",
    "\n",
    "# define the missing parameters within the config file. \n",
    "# window_size = size of the sliding window in units\n",
    "# nb_channels = number of feature channels\n",
    "# nb_classes = number of classes that can be predicted\n",
    "config['window_size'] = X_train.shape[1]\n",
    "config['nb_channels'] = X_train.shape[2]\n",
    "config['nb_classes'] = len(class_names)\n",
    "\n",
    "# initialize your DeepConvLSTM object \n",
    "network = DeepConvLSTM(config)\n",
    "\n",
    "# sends network to the GPU and sets it to training mode\n",
    "network.to(config['gpu_name'])\n",
    "network.train()\n",
    "\n",
    "# initialize the optimizer and loss\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# initializes the train and validation dataset in Torch format\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
    "    \n",
    "# define the train- and valloader; use from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)    \n",
    "valloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "# define your training loop; iterates over the number of epochs\n",
    "for e in range(config['epochs']):\n",
    "    # helper objects needed for proper documentation\n",
    "    train_losses = []\n",
    "    train_preds = []\n",
    "    train_gt = []\n",
    "    start_time = time.time()\n",
    "    batch_num = 1\n",
    "\n",
    "    # iterate over the trainloader object (it'll return batches which you can use)\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "        # sends batch x and y to the GPU\n",
    "        inputs, targets = x.to(config['gpu_name']), y.to(config['gpu_name'])\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # send inputs through network to get predictions\n",
    "        train_output = network(inputs)\n",
    "\n",
    "        # calculates loss\n",
    "        loss = criterion(train_output, targets.long())\n",
    "\n",
    "        # backprogate your computed loss through the network\n",
    "        # use the .backward() and .step() function on your loss and optimizer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate actual predictions (i.e. softmax probabilites); use torch.nn.functional.softmax()\n",
    "        train_output = torch.nn.functional.softmax(train_output, dim=1)\n",
    "\n",
    "        # appends the computed batch loss to list\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # creates predictions and true labels; appends them to the final lists\n",
    "        y_preds = np.argmax(train_output.cpu().detach().numpy(), axis=-1)\n",
    "        y_true = targets.cpu().numpy().flatten()\n",
    "        train_preds = np.concatenate((np.array(train_preds, int), np.array(y_preds, int)))\n",
    "        train_gt = np.concatenate((np.array(train_gt, int), np.array(y_true, int)))\n",
    "\n",
    "        # prints out every 100 batches information about the current loss and time per batch\n",
    "        if batch_num % 100 == 0 and batch_num > 0:\n",
    "            cur_loss = np.mean(train_losses)\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d} batches | ms/batch {:5.2f} | train loss {:5.2f}'.format(e, batch_num, elapsed * 1000 / config['batch_size'], cur_loss))\n",
    "            start_time = time.time()\n",
    "            batch_num += 1\n",
    "\n",
    "    # helper objects\n",
    "    val_preds = []\n",
    "    val_gt = []\n",
    "    val_losses = []\n",
    "\n",
    "    # sets network to eval mode and \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        # iterate over the valloader object (it'll return batches which you can use)\n",
    "        for i, (x, y) in enumerate(valloader):\n",
    "            # sends batch x and y to the GPU\n",
    "            inputs, targets = x.to(config['gpu_name']), y.to(config['gpu_name'])\n",
    "\n",
    "            # send inputs through network to get predictions\n",
    "            val_output = network(inputs)\n",
    "\n",
    "            # calculates loss by passing criterion both predictions and true labels \n",
    "            val_loss = criterion(val_output, targets.long())\n",
    "\n",
    "            # calculate actual predictions (i.e. softmax probabilites); use torch.nn.functional.softmax() on dim=1\n",
    "            val_output = torch.nn.functional.softmax(val_output, dim=1)\n",
    "\n",
    "            # appends validation loss to list\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "            # creates predictions and true labels; appends them to the final lists\n",
    "            y_preds = np.argmax(val_output.cpu().numpy(), axis=-1)\n",
    "            y_true = targets.cpu().numpy().flatten()\n",
    "            val_preds = np.concatenate((np.array(val_preds, int), np.array(y_preds, int)))\n",
    "            val_gt = np.concatenate((np.array(val_gt, int), np.array(y_true, int)))\n",
    "\n",
    "        # print epoch evaluation results for train and validation dataset\n",
    "        print(\"\\nEPOCH: {}/{}\".format(e + 1, config['epochs']),\n",
    "                  \"\\nTrain Loss: {:.4f}\".format(np.mean(train_losses)),\n",
    "                  \"Train Acc: {:.4f}\".format(jaccard_score(train_gt, train_preds, average='macro')),\n",
    "                  \"Train Prec: {:.4f}\".format(precision_score(train_gt, train_preds, average='macro')),\n",
    "                  \"Train Rcll: {:.4f}\".format(recall_score(train_gt, train_preds, average='macro')),\n",
    "                  \"Train F1: {:.4f}\".format(f1_score(train_gt, train_preds, average='macro')),\n",
    "                  \"\\nVal Loss: {:.4f}\".format(np.mean(val_losses)),\n",
    "                  \"Val Acc: {:.4f}\".format(jaccard_score(val_gt, val_preds, average='macro')),\n",
    "                  \"Val Prec: {:.4f}\".format(precision_score(val_gt, val_preds, average='macro')),\n",
    "                  \"Val Rcll: {:.4f}\".format(recall_score(val_gt, val_preds, average='macro')),\n",
    "                  \"Val F1: {:.4f}\".format(f1_score(val_gt, val_preds, average='macro')))\n",
    "\n",
    "        # if chosen, print the value counts of the predicted labels for train and validation dataset\n",
    "        if config['print_counts']:\n",
    "            print('Predicted Train Labels: ')\n",
    "            print(np.vstack((np.nonzero(np.bincount(train_preds))[0], np.bincount(train_preds)[np.nonzero(np.bincount(train_preds))[0]])).T)\n",
    "            print('Predicted Val Labels: ')\n",
    "            print(np.vstack((np.nonzero(np.bincount(val_preds))[0], np.bincount(val_preds)[np.nonzero(np.bincount(val_preds))[0]])).T)\n",
    "\n",
    "\n",
    "    # set network to train mode again\n",
    "    network.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0pirE87l6vK"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUVSpp-7l-QI"
   },
   "source": [
    "<a id=\"1\">[1]</a>   Francisco Javier Ordóñez and Daniel Roggen. 2016. \n",
    "Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition.\n",
    "Sensors 16, 1 (2016).  https://doi.org/10.3390/s16010115\n",
    "\n",
    "<a id=\"2\">[2]</a>   Marius Bock, Alexander Hoelzemann, Michael Moeller, and Kristof Van Laerhoven. 2021. Improving Deep Learning for HAR with Shallow LSTMs. In Proceedings of the 2021 International Symposium on Wearable Computers, ISWC 2021, September 21-26, 2021, ACM. https://doi.org/10.1145/3460421.3480419"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
